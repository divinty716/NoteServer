# 新入职准备工作

## Typora使用笔记

**视图展开**

文件 --》偏好设置 --》外观 --》 侧边栏 --》勾选侧边栏的大纲视图允许折叠和展开



**高亮快捷键**： == ==



**偏好设置优先使用相对路径**



**段落模板配置**



**笔记提交命令流程**：

```
git clone git@hithub.com:divinty716/noteServer  filename
git add .
git add filename/
git commit -m "xxx"
git push
git pull

```

## idea快捷键

### 通用操作

| 操作描述               | Windows/Linux 快捷键     | Mac 快捷键             |
| ---------------------- | ------------------------ | ---------------------- |
| 搜索一切               | `Double Shift`           | `Double Shift`         |
| 快速打开类             | `Ctrl + N`               | `Command + O`          |
| 快速打开文件           | `Ctrl + Shift + N`       | `Command + Shift + O`  |
| 快速打开符号           | `Ctrl + Alt + Shift + N` | `Command + Option + O` |
| 全局搜索和替换         | `Ctrl + Shift + R`       | `Command + Shift + R`  |
| 查找并替换（当前文件） | `Ctrl + R`               | `Command + R`          |
| 查找（当前文件）       | `Ctrl + F`               | `Command + F`          |

### 代码编辑

| 操作描述                                  | Windows/Linux 快捷键 | Mac 快捷键             |
| ----------------------------------------- | -------------------- | ---------------------- |
| 自动补全代码                              | `Ctrl + Space`       | `Control + Space`      |
| 快速修复                                  | `Alt + Enter`        | `Option + Enter`       |
| 格式化代码                                | `Ctrl + Alt + L`     | `Command + Option + L` |
| 复制当前行到下一行                        | `Ctrl + D`           | `Command + D`          |
| 删除当前行                                | `Ctrl + Y`           | `Command + Delete`     |
| 注释 / 取消注释当前行或选中代码（行注释） | `Ctrl + /`           | `Command + /`          |
| 注释 / 取消注释选中代码（块注释）         | `Ctrl + Shift + /`   | `Command + Shift + /`  |
| 移动当前行上下位置                        | `Alt + Shift + ↑/↓`  | `Option + Shift + ↑/↓` |
| 大小写转换                                | `Ctrl + Shift + U`   | `Command + Shift + U`  |

### 代码导航

| 操作描述              | Windows/Linux 快捷键            | Mac 快捷键                            |
| --------------------- | ------------------------------- | ------------------------------------- |
| 跳转到方法 / 类定义处 | `Ctrl + B` 或 `Ctrl + 鼠标左键` | `Command + B` 或 `Command + 鼠标左键` |
| 返回上次编辑位置      | `Ctrl + Alt + ←`                | `Command + Option + ←`                |
| 前进到下次编辑位置    | `Ctrl + Alt + →`                | `Command + Option + →`                |
| 查看类的继承结构      | `Ctrl + H`                      | `Command + H`                         |
| 查看方法调用层级      | `Ctrl + Alt + H`                | `Command + Option + H`                |
| 查看文件结构          | `Ctrl + F12`                    | `Command + F12`                       |

### 代码调试

| 操作描述             | Windows/Linux 快捷键 | Mac 快捷键            |
| -------------------- | -------------------- | --------------------- |
| 启动调试             | `Shift + F9`         | `Control + Shift + D` |
| 单步跳过             | `F8`                 | `F8`                  |
| 单步进入             | `F7`                 | `F7`                  |
| 跳出方法             | `Shift + F8`         | `Shift + F8`          |
| 继续执行到下一个断点 | `F9`                 | `F9`                  |

### 版本控制

| 操作描述             | Windows/Linux 快捷键 | Mac 快捷键    |
| -------------------- | -------------------- | ------------- |
| 提交代码             | `Ctrl + K`           | `Command + K` |
| 拉取代码             | `Ctrl + T`           | `Command + T` |
| 查看版本控制工具窗口 | `Alt + 9`            | `Option + 9`  |

# 讯飞项目管理

##  运营系统

### **用户请求诊断**：

**功能介绍**：对用户搜索后的错误返回进行人工修正和诊断，提问理解或者语义拆分进行分析，展示服务端精排粗排重排结果，人工干预排序和打分

qa数据同时存在在运营系统和大数据爬虫平台：主要title、summary、content三部分【来源、置信度、召回数量、相关性、置信度】

【**1.**】大数据组通过kafka写，时政/国家新闻敏感数据【与业务场景有关】通过redis每日刷入更新

【**2.**】构造延迟队列解决数据完整性问题，qa数据实时落库，核对数据发现跨天数据缺失，基于redis的sorted set构造了延迟队列将跨天前10分钟的数据保存进行二次消费

**【3.**】异步批处理qa数据并落库，多线程+bacthinsert，saveList【mongo】

【**4.**】请求评测，分词重写，支持qa分析与编辑，请求诊断使用es读取服务端的分词结果+用jsonNode【前缀】解析结果搜索服务的重排精排高亮结果。 

```java
// 分词
objectMapper.readTree(jsonNode.at("/Msg/SegResult").asText())
        .at("/0/qu_response/qu_results").forEach(e -> {
            if (e.at("/seg_result/segMode").asInt() == 0L) {
                AtomicInteger idx = new AtomicInteger(1);
                e.at("/seg_result/words").forEach(word -> {
                    // noinspection unchecked
                    segList.add(new SegResultVO(
                            idx.getAndIncrement(),
                            word.at("/tag").asText(),
                            word.at("/weight").asDouble(),
                            word.at("/word").asText(),
                            objectMapper.convertValue(word.at("/synonyms"), ArrayList.class)
                    ));
                });
            }
        });
```

### **领域库管理**：

**功能介绍**：爬虫组爬取的网页信息经过数据解析后会进入设计好的13个领域库，科学医疗教育编程旅游等等，这些数据在milvus会形成向量库数据，运营系统需要有统一查看领域库数据，对数据提供编辑删除查询黑名单等功能，在流程中通过中间表维护回滚操作。单表千万~亿级别的查询，故障混滚保障。

**主流程：**

顺序：先milvius再manticoreSearch再mongo

**【一】**编辑与删除--主要在于修改title和summary

1.修改title+summary通过服务重新获取向量结果，创建两个中间表，一个记录完整的数据+更新前后的信息，一个维护主要的id title和状态【便于回查问题】

2.先修删除milvius再新增的方式更新

3.更具新增的调用manticoreSearch重新分词并更新【summary、content的lac和jieba分词】

4.更新mongo领域库次词条信息

5.成功删除记录表只维护标记表

过程中涉及调用其他服务，catch中如果出现任意的异常，则根据反序回滚

**【二】**查询与检索，嵌套线程池

在库的层级建立  List<Callable<Boolean>> callableList = new ArrayList<>();

**外层**一个List包启用多线程的Callable对象任务列表，每个对象都是查询不同的库

提交到线程池  futures.add(EXECUTOR.submit(callable));

**内层**

- 将`Future`对象转换为`CompletableFuture`，以便可以使用更强大的异步编程功能。
- 每个`CompletableFuture`在获取结果时设置了500毫秒的超时时间。如果超时或发生异常，返回`null`并记录错误日志。



List<Callable<IURLMongoInfoDownloadDto>> 

```java
private IURLMongoInfoDownloadDto getMongoInfo(String url){
        if (url==null) {
            return null;
        }
        List<Callable<IURLMongoInfoDownloadDto>> callableList = new ArrayList<>();
        Arrays.stream(ParseCollectionEnum.values()).forEach(ce -> {
            callableList.add(() -> doFindFromDb(url, ce));
        });

        try {
            List<Future<IURLMongoInfoDownloadDto>> futures = new ArrayList<>();
            for (Callable<IURLMongoInfoDownloadDto> callable : callableList) {
                futures.add(EXECUTOR.submit(callable));
            }
            List<CompletableFuture<IURLMongoInfoDownloadDto>> futureList = futures.stream()
                    .map(f -> CompletableFuture.supplyAsync(() -> {
                        try {
                            return f.get(500, TimeUnit.MILLISECONDS);
                        } catch (Exception e) {
                            log.error("[QueryParseResult result = f.get(1000, TimeUnit.MILLISECONDS)] future get err: ", e);
                            return null;
                        }
                    }))
                    .collect(Collectors.toList());
            CompletableFuture<Void> allFuturesResult = CompletableFuture.allOf(futureList.toArray(new CompletableFuture[0]));
            allFuturesResult.get();
            List<IURLMongoInfoDownloadDto> resultList = new ArrayList<>();
            futureList.forEach(f ->{
                try {
                    if(f.get() != null){
                        resultList.add(f.get());
                    }
                } catch (InterruptedException | ExecutionException e) {
                    log.error("获取 CompletableFuture 结果时出错: ", e);
                    // 在这里处理异常情况，例如添加默认值或者进行其他逻辑处理
                    resultList.add(null);
                }
            });

            if(CollectionUtils.isEmpty(resultList)){
                return null;
            }else {
                return resultList.stream().filter(Objects::nonNull).collect(Collectors.toList()).get(0);
            }
        }
        catch (Exception e) {
            log.error("doFindFromUrl err: ", e);
            return null;
        }
    }

    private IURLMongoInfoDownloadDto doFindFromDb(String url, ParseCollectionEnum ce){
        long id = MD5Utils.getMd5IdToLong(url);
        Query query = Query.query(Criteria.where("_id").is(id));
        IURLMongoInfoDownloadDto dto = mongoTemplateTwo.findOne(query, IURLMongoInfoDownloadDto.class, ce.getCollectionName());
        return dto;
    }
```

【三】懒加载式查询优化，url转id记录当前页的首尾id，灵活快速翻页

**疑问**

【1】**什么是milvius？什么是manticoreSearch**？

### 结果干预&离线召回

结果干预：请求诊断的详情中可以进行结果干预，同步到es

- **人工置顶**：将某些结果强制排在前面。
- **权重调整**：通过调整排序模型的权重，影响结果的排名。
- **过滤规则**：屏蔽某些不符合条件的结果。

离线召回的数据不可以人工干预排序结果，只对删除和是否启用多保留

![image-20230822102535339](E:\笔记\废弃日常材料z\image-20230822102535339.png)

**结合使用**

在实际搜索系统中，**结果干预**和**离线召回**通常是结合使用的：

1. **离线召回**负责从海量数据中筛选出高质量的候选集。
2. **在线排序**模型对候选集进行精细排序。
3. **结果干预**在最终展示阶段对排序结果进行调整，以满足业务需求或提升用户体验。

### 测试集管理

产生的原因测试同学在系统功能验证，以及搜索效果优化的过程中需要标注加工大量的数据，部分数据一直走的excel表格，录入库中也有很多格式问题。测试组长还期望能自定义展示的字段【标注字段很多】进行测试结果筛选，支持自定义的数据检索与或非逻辑的组合。

字段设置子模块：系统字段【强制展示】，非系统字段自由筛选添加，以用户维度建立了字段模板

【1】数据导入MultipartFile读文件夹，阿里的CustomExcelListener定制化解析excel表格的格式表头，数据大小等等

【2】递归筛选，与或非逻辑

**【3】与加工平台的结合**

```java
private List<Condition> recursionCondition(Condition condition, Map<Integer, Criteria> map, int level) {
    if (condition instanceof CompositeCondition) {
        CompositeCondition c = (CompositeCondition) condition;

        List<Condition> list = new ArrayList<>();
        for (Condition child : c.getChildren()) {
            list.addAll(recursionCondition(child, map, level + 1));
        }

        List<Criteria> criList = new ArrayList<>();
        list.forEach(i -> {
            LeafCondition item = (LeafCondition) i;
            Criteria criteria = fieldCriteria(item);
            if (null != criteria) {
                criList.add(criteria);
            }
        });

        Criteria criteria = new Criteria();
        if (!map.isEmpty() && map.containsKey(level + 1)) {
            criList.add(map.get(level + 1));
        }
        if (criList.size() == 1) {
            criteria = criList.get(0);
        } else {
            if (LogicOperatorEnum.AND.getCode().equals(c.getLogic())) {
                criteria.andOperator(criList);
            }
            if (LogicOperatorEnum.OR.getCode().equals(c.getLogic())) {
                criteria.orOperator(criList);
            }
        }

        map.put(level, criteria);

    } else if (condition instanceof LeafCondition) {
        return Collections.singletonList(condition);
    }
    return new ArrayList<>();
}
```

**逻辑**：

1. **处理复合条件（`CompositeCondition`）**：
   - 如果当前条件是复合条件（`CompositeCondition`），则递归处理其子条件。
   - 将子条件转换为 `Criteria` 并存储在 `criList` 中。
   - 根据复合条件的逻辑关系（AND/OR），使用 `andOperator` 或 `orOperator` 组合子条件。
   - 将组合后的 `Criteria` 存储在 `map` 中，键为当前层级（`level`）。
2. **处理叶子条件（`LeafCondition`）**：
   - 如果当前条件是叶子条件（`LeafCondition`），则直接返回该条件。
   - 叶子条件通常表示具体的字段查询条件（如 `field = value`）。
3. **返回结果**：
   - 对于复合条件，返回空列表（因为结果已经存储在 `map` 中）。
   - 对于叶子条件，返回包含该条件的单元素列表。

### 数据版本管理

需求产生：每周数据版本更新，同步3M数据，爬虫组临时发起数据更新发起我们配合总有数据无法对齐，服务互相影响的问题，mongo库的大小也受到了限制



上线下线的接口由服务端提供

数据同步的发起由爬虫组提供

运营中台用于核对bucket中的数据信息文件



3M数据信息文件

master表保存3m主表信息

 manager表保存各自3M库表的分区信息，

流程：

爬虫组发起上线冒烟测试---运营系统通知服务端冒烟测试数据同步--同步完成回传运营系统调用Minio Bucket存的Master表核对数据量是否一致---一致冒烟测试通过通知服务端全量上线--报错邮件告知服务端，日志记录终止上线回滚



### **什么是Minio？**

MinIO 是一个高性能、分布式、云原生的**对象存储系统**。它兼容 Amazon S3 API，可以用于存储和管理非结构化数据（如图片、视频、日志文件等）。MinIO 的设计目标是提供简单易用、高性能且可扩展的存储解决方案，适用于现代云原生应用和大数据场景。

#### **MinIO 的核心概念**

1. **Bucket（存储桶）**：
   - 类似于文件夹，用于组织和管理对象（文件）。
   - 每个 Bucket 可以有独立的权限和策略。
2. **Object（对象）**：
   - 存储在 MinIO 中的基本单元，可以是任意类型的文件。
3. **S3 API**：
   - MinIO 完全兼容 Amazon S3 API，支持标准的 S3 操作（如上传、下载、删除等）。
4. **分布式模式**：
   - MinIO 支持分布式部署，数据可以分散存储在多个节点上，提供高可用性和数据冗余。



#### 为什么 MinIO 适合存储 Milvus 和 ManticoreSearch

1. **高吞吐和低延迟**：
   - **Milvus**：作为向量数据库，Milvus 需要高效存储和检索大量向量数据，MinIO 的高吞吐和低延迟特性能够满足其需求。
   - **ManticoreSearch**：作为全文搜索引擎，ManticoreSearch 需要快速访问大量文档数据，MinIO 的性能优势有助于提升搜索效率。
2. **可扩展性**：
   - **Milvus**：随着数据量增长，MinIO 的分布式架构可以轻松扩展存储容量。
   - **ManticoreSearch**：MinIO 的扩展性支持其处理不断增长的文档数据。
3. **高可用性**：
   - **Milvus**：MinIO 的高可用性确保向量数据在节点故障时仍可访问。
   - **ManticoreSearch**：MinIO 的数据冗余和故障恢复机制保障搜索服务的连续性。
4. **兼容性**：
   - **Milvus** 和 **ManticoreSearch** 都可以通过 S3 API 与 MinIO 集成，简化了存储管理。

#### MinIO实例

ListObjectsArgs，RemoveObjectArgs

```java
/**
 * @param cluster
 * @param bucketName
 * 获取minio下bucket文件夹下的列表
 */
@Override
public List<String> listFilesInBucket(String cluster, String bucketName) {
    if (StringUtils.isEmpty(cluster) || !minioClientMap.containsKey(cluster)) {
        throw new IllegalArgumentException("Cluster is empty or not found in the map: " + cluster);
    }
    try {
        List<String> fileNames = new ArrayList<>();
        String continuationToken = null;
        do {
            ListObjectsArgs args = ListObjectsArgs.builder()
                    .bucket(bucketName)
                    .continuationToken(continuationToken)
                    .build();
            Iterable<Result<io.minio.messages.Item>> results = minioClientMap.get(cluster).listObjects(args);
            for (Result<io.minio.messages.Item> result : results) {
                io.minio.messages.Item item = result.get();
                if (item.isDir()) {
                    continue; // 跳过目录
                }
                fileNames.add(item.objectName());
            }
            // 检查是否有更多的对象可以列出
            continuationToken = args.continuationToken();
        } while (continuationToken != null);
        return fileNames;
    } catch (Exception e) {
        log.error("获取minio文件下的文件列表出现异常: {}", e.getMessage(), e);
    }
    return null;
}
```

```java
 /**
     * @author yffeng4
     * @Date: 2024/2/27 10:57
     * @Description: 根据bucket名称删除其中对应的数据
     **/
    @Override
    public boolean deleteDataFromBucket(String cluster, String bucketName) {
        if (StringUtils.isEmpty(cluster) || !minioClientMap.containsKey(cluster)) {
            throw new IllegalArgumentException("Cluster is empty or not found in the map: " + cluster);
        }
        try {
            boolean isTruncated = true;
            String continuationToken = null;
            while (isTruncated) {
                ListObjectsArgs args = ListObjectsArgs.builder()
                        .bucket(bucketName)
                        .continuationToken(continuationToken)
                        .recursive(true)
                        .build();
                Iterable<Result<io.minio.messages.Item>> results = minioClientMap.get(cluster).listObjects(args);
                for (Result<io.minio.messages.Item> result : results) {
                    Item item = result.get();
                    String objectName = item.objectName();

                    RemoveObjectArgs removeObjectArgs = RemoveObjectArgs.builder()
                            .bucket(bucketName)
                            .object(objectName)
                            .build();
                    minioClientMap.get(cluster).removeObject(removeObjectArgs);
                }
                // 检查是否有更多的对象可以列出
                continuationToken = args.continuationToken();
                isTruncated = continuationToken != null;
            }
            RemoveBucketArgs removeBucketArgs = RemoveBucketArgs.builder()
                    .bucket(bucketName)
                    .build();
            minioClientMap.get(cluster).removeBucket(removeBucketArgs);
            return true;
        } catch (Exception e) {
            log.error("删除bucket下的数据时出现异常: {}", e.getMessage(), e);
            return false;
        }
    }
```

### 什么是粗排、精排、重排

#### 粗排（Coarse Ranking）

- 定义
  - 粗排是搜索系统排序流程的第一个阶段，它的主要任务是从海量的候选文档集合中快速筛选出一部分相对优质的文档，减少后续精排阶段需要处理的数据量，以提高系统的整体效率。
- 特点
  - **速度快**：由于需要处理大量的候选文档，粗排算法通常比较简单、计算量小，能够在短时间内完成筛选。
  - **精度相对较低**：不会使用过于复杂的特征和模型来进行排序，只是进行一个初步的筛选。
- 实现方式
  - 一般会使用一些简单的特征和算法，如基于词频 - 逆文档频率（TF - IDF）、文本相似度等进行快速打分和排序。例如，在一个电商搜索系统中，粗排可能会根据商品标题与搜索关键词的匹配程度、商品的销量等简单特征，快速从数百万个商品中筛选出几千个商品进入下一轮排序。

#### 精排（Fine Ranking）



- 定义
  - 精排是在粗排筛选出的候选文档集合基础上，进行更细致、精确的排序。它会综合考虑更多的特征和因素，以提供更符合用户需求的搜索结果排序。
- 特点
  - **精度高**：会使用复杂的特征工程和强大的机器学习模型，充分考虑各种可能影响用户对搜索结果满意度的因素。
  - **计算资源消耗大**：由于需要处理更多的特征和使用更复杂的模型，精排的计算量相对较大，处理速度相对较慢。
- 实现方式
  - 通常会使用深度学习模型，如深度神经网络（DNN）、梯度提升决策树（GBDT）等。在训练模型时，会使用大量的标注数据，考虑多种特征，如用户的历史行为数据（点击、购买、收藏等）、文档的质量特征（内容质量、权威性等）、上下文信息等。例如，在搜索引擎中，精排会结合用户的搜索历史、当前搜索的上下文、网页的质量得分等信息，对粗排筛选出的结果进行精确排序。

#### 重排（Re - ranking）

- 定义
  - 重排是在精排结果的基础上，根据一些特定的规则或实时信息对搜索结果进行再次排序，以进一步优化搜索结果的排序质量。
- 特点
  - **灵活性高**：可以根据不同的业务需求和实时情况进行动态调整，以满足多样化的排序需求。
  - **通常考虑局部信息**：更关注当前搜索结果集合内的文档之间的关系和特定的业务规则。
- 实现方式
  - 重排的实现方式多种多样，可以基于规则，也可以使用简单的模型。例如，根据业务需求，将某些热门商品或广告置顶；或者根据实时的用户反馈信息（如当前页面的点击率）对搜索结果进行实时调整。在新闻搜索系统中，可能会根据新闻的时效性，对精排结果进行重排，将最新的新闻排在前面。

## 知识库加工平台

### 数据集管理

运营、测试、百科、QA数据，支持多条件、多格式、多段的数据导出

### 标注工作台

标注任务:task表，一个表只可能有多个数据集--数据池

用户任务表：user_task表，每个用户可以从一个标注任务中领取一个或多个数据集进行标注领取后生成task_batch

数据集批次表：task_batch，每有若干个用户领取若干个任务都会在对应的标注任务下形成数据批次，用于监控数据集标注完成数量

任务词条表：task_item,对待标注的词条进行人工标注

用户任务步骤表：user_task_step,任务分标注、检查、质检多个步骤

### 自建知识库上线管理

--针对于特殊数据和人工标注的数据

【1】爱标客数据、星图数据、医疗数据、时政数据、百科数据、qa数据。Ai资源部爱标客数据、六种数据

【2】各自有格式，面向其业务，设计了6种自建知识库的入库方式，6个大接口

【3】统一解析成一个模板，有些kafka有些redis有些es，调用其它接口

【4】首先汇总到知识库加工平台mongo库中

【5】发起数据版本上线，冒烟测试，再全量写3M库构建文本索引和向量索引，中台--》爬虫平台&服务端

【6】自建知识库每次量级不大，上线速度快，一般告警先通过日志终止查找问题，再走线上环境

### 其他模块

如数据报表、标注团队管理、异常数据管理

## 用户中心服务

### **个人中心集中配置**

依托Springboot可灵活配置特性,设计Config类支持部分功能和属性的灵活配置

### **个人中心用户信息**

对教育bg所有用户个人信息根据不同业务条线结合角色、学区进行展示与编辑

### **手机号邮箱密码管理**

集合redis设计Token进行全流程安全校验，支持三种登录方式的绑定解绑换绑

需要多步验证的，给出串行redis的token防止跳步

### **三方账号管理**

集成微信微博QQ三方账号api，根据业务支持关联账号、孩子账号、三方账号的绑定解绑

经过调研，配置统一的请求发送工具类，调用对应的api，根据返回结果在库

### 日志记录组件

```java
import org.aspectj.lang.JoinPoint;
import org.aspectj.lang.annotation.AfterReturning;
import org.aspectj.lang.annotation.AfterThrowing;
import org.aspectj.lang.annotation.Aspect;
import org.aspectj.lang.reflect.MethodSignature;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;

import java.lang.reflect.Method;

@Aspect
@Component
public class LogAspect {
    @Autowired
    private KafkaLogProducer kafkaLogProducer;

    @AfterReturning(pointcut = "execution(* com.example.usercenter.controller.*.*(..))", returning = "result")
    public void logAfterReturning(JoinPoint joinPoint, Object result) {
        recordLog(joinPoint, true);
    }

    @AfterThrowing(pointcut = "execution(* com.example.usercenter.controller.*.*(..))", throwing = "ex")
    public void logAfterThrowing(JoinPoint joinPoint, Throwable ex) {
        recordLog(joinPoint, false);
    }

    private void recordLog(JoinPoint joinPoint, boolean success) {
        MethodSignature signature = (MethodSignature) joinPoint.getSignature();
        Method method = signature.getMethod();
        String interfaceName = method.getName();
        String userId = getUserIdFromArgs(joinPoint.getArgs());

        LogEntity log = new LogEntity();
        log.setUserId(userId);
        log.setAction(interfaceName);
        log.setInterfaceName(interfaceName);
        log.setSuccess(success);

        kafkaLogProducer.sendLog(log);
    }

    private String getUserIdFromArgs(Object[] args) {
        // 这里简单假设第一个参数是用户 ID，实际中根据情况修改
        return args.length > 0 ? args[0].toString() : "unknown";
    }
}
```

日志服务搜索器

```java
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.data.elasticsearch.core.ElasticsearchOperations;
import org.springframework.data.elasticsearch.core.SearchHit;
import org.springframework.data.elasticsearch.core.SearchHits;
import org.springframework.data.elasticsearch.core.query.Criteria;
import org.springframework.data.elasticsearch.core.query.CriteriaQuery;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.bind.annotation.RestController;

import java.util.ArrayList;
import java.util.List;

@RestController
public class LogSearchController {
    @Autowired
    private ElasticsearchOperations elasticsearchOperations;

    @GetMapping("/logs/search")
    public List<LogEntity> searchLogs(@RequestParam(required = false) String userId,
                                      @RequestParam(required = false) String interfaceName,
                                      @RequestParam(required = false) Boolean success) {
        Criteria criteria = new Criteria();
        if (userId != null) {
            criteria.and("userId").is(userId);
        }
        if (interfaceName != null) {
            criteria.and("interfaceName").is(interfaceName);
        }
        if (success != null) {
            criteria.and("success").is(success);
        }

        CriteriaQuery query = new CriteriaQuery(criteria);
        SearchHits<LogEntity> searchHits = elasticsearchOperations.search(query, LogEntity.class);
        List<LogEntity> logs = new ArrayList<>();
        for (SearchHit<LogEntity> hit : searchHits) {
            logs.add(hit.getContent());
        }
        return logs;
    }
}
```

## **UC-权限管理系统**

用户赋予角色，角色绑定菜单，菜单赋予功能

妥协的方式

●**接口鉴权：**结合Spring security,filterInvocation中获取请求，Authentation中解析用户角色，根据数据库的灵活配置将访问请求与允许该角色访问的路径进行匹配鉴权，保护系统的安全与机密性。

## 回流日志服务改造

# 携程项目管理

# Docker

**Docker** 是一个开源的容器化平台，用于开发、部署和运行应用程序。它通过将应用程序及其依赖项打包到一个轻量级的容器中，使应用程序可以在任何环境中一致运行。Docker 容器与虚拟机不同，容器共享主机操作系统的内核，因此更加轻量、启动更快、资源占用更少。

## Docker 的核心概念：

1. **镜像（Image）**：一个只读模板，包含运行应用程序所需的代码、库、环境变量和配置文件。
2. **容器（Container）**：镜像的运行实例，是一个独立的、可执行的进程。
3. **Dockerfile**：一个文本文件，包含构建镜像的指令。
4. **仓库（Registry）**：用于存储和分发 Docker 镜像的服务，如 Docker Hub。

## 上传docker镜像

### **创建 Docker 镜像**

**方法 1：通过 Dockerfile 构建镜像**

Dockerfile 是一个文本文件，包含构建镜像的指令。以下是创建镜像的步骤：

1. **编写 Dockerfile**
   在项目根目录下创建一个名为 `Dockerfile` 的文件，内容示例如下：

   Dockerfile

   复制

   ```
   # 使用基础镜像
   FROM ubuntu:20.04
   
   # 设置工作目录
   WORKDIR /app
   
   # 复制文件到容器中
   COPY . .
   
   # 安装依赖
   RUN apt-get update && apt-get install -y python3
   
   # 暴露端口
   EXPOSE 80
   
   # 设置启动命令
   CMD ["python3", "app.py"]
   ```

2. **构建镜像**
   在 Dockerfile 所在目录下运行以下命令：

   bash

   复制

   ```
   docker build -t <镜像名>:<标签> .
   ```

   例如：

   bash

   复制

   ```
   docker build -t myapp:1.0 .
   ```

   - `-t`：指定镜像的名称和标签。
   - `.`：表示 Dockerfile 所在的当前目录。

3. **查看本地镜像**
   构建完成后，可以通过以下命令查看本地镜像：

   bash

   复制

   ```
   docker images
   ```

**方法 2：通过容器创建镜像**

如果你已经有一个正在运行的容器，可以基于该容器创建镜像：

1. **运行容器**：

   bash

   复制

   ```
   docker run -it ubuntu:20.04 /bin/bash
   ```

2. **在容器中修改内容**：
   例如，安装一些软件：

   bash

   复制

   ```
   apt-get update && apt-get install -y curl
   ```

3. **提交容器为镜像**：
   退出容器后，运行以下命令：

   bash

   复制

   ```
   docker commit <容器ID> <镜像名>:<标签>
   ```

   例如：

   bash

   复制

   ```
   docker commit abc123 myapp:1.0
   ```

------

### **上传 Docker 镜像到仓库**

Docker 镜像可以上传到 Docker Hub 或其他私有仓库（如 AWS ECR、阿里云容器镜像服务等）。以下是上传到 Docker Hub 的步骤：

**步骤 1：登录 Docker Hub**

1. 如果没有 Docker Hub 账号，先注册一个：[Docker Hub](https://hub.docker.com/)。

2. 使用以下命令登录：

   bash

   复制

   ```
   docker login
   ```

   输入用户名和密码。

**步骤 2：为镜像打标签**

在上传之前，需要为本地镜像打上符合 Docker Hub 命名规范的标签：

bash

复制

```
docker tag <本地镜像名>:<标签> <Docker Hub用户名>/<镜像名>:<标签>
```

例如：

bash

复制

```
docker tag myapp:1.0 mydockerhubusername/myapp:1.0
```

**步骤 3：上传镜像**

使用以下命令上传镜像：

bash

复制

```
docker push <Docker Hub用户名>/<镜像名>:<标签>
```

例如：

bash

复制

```
docker push mydockerhubusername/myapp:1.0
```

**步骤 4：验证上传**

登录 Docker Hub，在仓库中查看是否成功上传。

bash

复制

```
docker push <私有仓库URI>/<镜像名>:<标签>
```

------

### 示例：完整流程

1. **编写 Dockerfile**：

   Dockerfile

   复制

   ```
   FROM nginx:latest
   COPY index.html /usr/share/nginx/html
   EXPOSE 80
   ```

2. **构建镜像**：

   bash

   复制

   ```
   docker build -t mynginx:1.0 .
   ```

3. **打标签**：

   bash

   复制

   ```
   docker tag mynginx:1.0 mydockerhubusername/mynginx:1.0
   ```

4. **上传镜像**：

   bash

   docker push <私有仓库URI>/<镜像名>:<标签>

# k8s

## 命令

`kubectl` 是 Kubernetes 的命令行工具，用于与 Kubernetes 集群进行交互。通过 `kubectl`，用户可以管理集群中的资源，如部署应用、查看日志、调试服务等。

### 集群管理

1. **查看集群信息**：

   bash

   复制

   ```
   kubectl cluster-info
   ```

2. **查看节点状态**：

   bash

   复制

   ```
   kubectl get nodes
   ```

### 资源管理

1. **查看所有资源**：

   bash

   复制

   ```
   kubectl get all
   ```

2. **查看 Pod**：

   bash

   复制

   ```
   kubectl get pods
   ```

3. **查看 Service**：

   bash

   复制

   ```
   kubectl get services
   ```

4. **查看 Deployment**：

   bash

   复制

   ```
   kubectl get deployments
   ```

5. **查看命名空间**：

   bash

   复制

   ```
   kubectl get namespaces
   ```

# Redis



# 多线程

##  CountDownLatch（倒计时门闩）

### 基本概念

`CountDownLatch`是 Java 中的一个同步工具类，位于`java.util.concurrent`包下。它允许一个或多个线程等待其他线程完成操作。`CountDownLatch`内部维护一个计数器，初始化时设定一个整数值，每当一个线程完成任务后，计数器的值减 1，当计数器的值变为 0 时，所有等待的线程将被释放。

**核心特点**

- **一次性使用**：计数器只能被初始化一次，减到0后就不能再重置
- **等待机制**：调用`await()`的线程会被阻塞，直到计数器减到0
- **不可循环使用**：计数器归零后就不能再次使用

 **适用场景**

- 主线程等待多个子线程完成任务后再继续执行
- 多个线程等待某个条件达成后同时开始执行
- 测试并发场景时模拟多线程准备就绪

### 使用方法

模板：

```java
CountDownLatch latch = new CountDownLatch(N); // 初始化计数器
// 工作线程
latch.countDown(); // 计数器减1
// 等待线程
latch.await(); // 阻塞直到计数器为0
```

案例：火箭发射准备检查

```java
public class RocketLaunch {
    public static void main(String[] args) throws InterruptedException {
        final int TASKS = 5;
        CountDownLatch preLaunchCheck = new CountDownLatch(TASKS);
        
        // 模拟5个系统检查线程
        for (int i = 1; i <= TASKS; i++) {
            new Thread(new SystemCheck("System-"+i, preLaunchCheck)).start();
        }
        
        // 主线程等待所有检查完成
        preLaunchCheck.await();
        System.out.println("所有系统检查完成，准备发射火箭！");
    }
}

class SystemCheck implements Runnable {
    private final String systemName;
    private final CountDownLatch latch;
    
    public SystemCheck(String name, CountDownLatch latch) {
        this.systemName = name;
        this.latch = latch;
    }
    
    @Override
    public void run() {
        try {
            // 模拟检查耗时
            Thread.sleep((long)(Math.random() * 3000));
            System.out.println(systemName + " 检查完成");
            latch.countDown();
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
        }
    }
}
```

### 经典案例

==**多个线程的按顺序执行**==

基本思路是为每个线程设置一个`CountDownLatch`，前一个线程完成任务后，调用`countDown()`方法使计数器减 1，下一个线程则调用`await()`方法等待前一个线程完成。

```java
public class CountDownLatchOrderedThreads {
    public static void main(String[] args) {
        // 创建两个 CountDownLatch 实例，用于控制线程执行顺序
        CountDownLatch latch1 = new CountDownLatch(1);
        CountDownLatch latch2 = new CountDownLatch(1);

        // 创建第一个线程
        Thread thread1 = new Thread(() -> {
            System.out.println("Thread 1 is running.");
            // 线程 1 完成任务后，将 latch1 的计数器减 1
            latch1.countDown();
        });

        // 创建第二个线程
        Thread thread2 = new Thread(() -> {
            try {
                // 线程 2 等待线程 1 完成任务
                latch1.await();
                System.out.println("Thread 2 is running.");
                // 线程 2 完成任务后，将 latch2 的计数器减 1
                latch2.countDown();
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
            }
        });

        // 创建第三个线程
        Thread thread3 = new Thread(() -> {
            try {
                // 线程 3 等待线程 2 完成任务
                latch2.await();
                System.out.println("Thread 3 is running.");
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
            }
        });

        // 启动线程
        thread1.start();
        thread2.start();
        thread3.start();
    }
}    
```

控制同时执行的最大并发数

```java
public class CountDownLatchConcurrencyControl {
    public static void main(String[] args) {
        // 允许的最大并发线程数
        int maxConcurrency = 3;
        // 创建一个 CountDownLatch，初始计数器值为最大并发线程数
        CountDownLatch semaphore = new CountDownLatch(maxConcurrency);

        // 模拟 10 个任务
        for (int i = 0; i < 10; i++) {
            final int taskId = i;
            new Thread(() -> {
                try {
                    // 尝试获取许可，如果没有可用许可则等待
                    semaphore.await();
                    System.out.println("Task " + taskId + " is running.");
                    // 模拟任务执行
                    Thread.sleep((long) (Math.random() * 1000));
                    System.out.println("Task " + taskId + " has finished.");
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                } finally {
                    // 任务执行完毕，释放一个许可
                    semaphore.countDown();
                }
            }).start();
        }
    }

```



## CyclicBarrier

### 基本概念

`CyclicBarrier`也是 Java 中的一个同步工具类，同样位于`java.util.concurrent`包下。它允许一组线程相互等待，直到所有线程都到达一个公共的屏障点，然后所有线程可以继续执行。`CyclicBarrier`可以重复使用

### 核心特点

- **可循环使用**：屏障可以重复使用
- **线程会相互等待**：所有线程必须都到达屏障点才能继续执行
- **可定义屏障动作**：==当所有线程到达屏障时，可以执行一个Runnable任务==

### 适用场景

- 多个线程需要协作完成一个循环任务，每个线程在完成一部分工作后需要等待其他线程完成，然后一起进入下一轮循环
- 并行迭代算法中需要同步的步骤
- 需要多个线程同时开始执行的场景

### 使用方法

模板

```java
CyclicBarrier barrier = new CyclicBarrier(N); // N个线程的屏障
// 或
CyclicBarrier barrier = new CyclicBarrier(N, barrierAction); // 带有屏障动作

// 线程中
barrier.await(); // 等待其他线程
```

具体案例：多线程数据计算

```java
public class MatrixCalculation {
    private static final int ROWS = 3;
    private static int[][] matrix = {
        {1, 2, 3},
        {4, 5, 6},
        {7, 8, 9}
    };
    private static int[] rowResults = new int[ROWS];
    
    public static void main(String[] args) {
        // 创建屏障，当所有线程到达时执行汇总操作
        // 并定义当所有线程到达屏障时要执行的动作(汇总结果)
        CyclicBarrier barrier = new CyclicBarrier(ROWS, () -> {
            int total = 0;
            for (int result : rowResults) {
                total += result;
            }
            System.out.println("所有行计算完成，总和为: " + total);
        });
        
        // 为每行创建一个计算线程，每个线程要做的事
        for (int i = 0; i < ROWS; i++) {
            new Thread(new RowCalculator(i, barrier)).start();
        }
    }
}

class RowCalculator implements Runnable {
    private final int row;
    private final CyclicBarrier barrier;
    
    public RowCalculator(int row, CyclicBarrier barrier) {
        this.row = row;
        this.barrier = barrier;
    }
    
    @Override
    public void run() {
        try {
            // 计算当前行的和
            int sum = 0;
            for (int num : MatrixCalculation.matrix[row]) {
                sum += num;
            }
            MatrixCalculation.rowResults[row] = sum;
            System.out.println("第 " + (row+1) + " 行计算完成: " + sum);
            
            // 等待其他线程
            barrier.await();
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}
```





## 对比以及选择建议

| 特性     | CountDownLatch       | CyclicBarrier            |
| :------- | :------------------- | :----------------------- |
| 重用性   | 一次性使用           | 可重复使用               |
| 计数器   | 只能减不能增         | 自动重置                 |
| 等待机制 | 线程等待计数器归零   | 线程相互等待             |
| 屏障动作 | 无                   | 可定义屏障到达时的动作   |
| 适用场景 | 一个线程等待多个线程 | 多个线程相互等待         |
| 异常处理 | 计数操作不会抛出异常 | 如果线程被中断会抛出异常 |

建议

- 当需要**一个或多个线程等待其他线程完成操作**时，使用**CountDownLatch**
- 当需要**一组线程相互等待，到达共同屏障点后再继续执行**时，使用**CyclicBarrier**
- 如果需要**重复使用同步机制**，选择**CyclicBarrier**
- 如果只需要**简单的完成信号**，选择**CountDownLatch**



## Thread创建线程

### Thread类经典用法

创建线程的两种主要方式：

==方式一：继承Thread类==

```
class MyThread extends Thread {
    @Override
    public void run() {
        // 线程执行的代码
        System.out.println("线程运行中: " + Thread.currentThread().getName());
    }
}

// 使用
MyThread thread = new MyThread();
thread.start();
```

==方式二：实现Runnable接口==

```
class MyRunnable implements Runnable {
    @Override
    public void run() {
        // 线程执行的代码
        System.out.println("线程运行中: " + Thread.currentThread().getName());
    }
}

// 使用
Thread thread = new Thread(new MyRunnable());
thread.start();
```

推荐用法

通常==**推荐实现Runnable接口**==的方式，因为：

- Java不支持多重继承，继承Thread类后无法继承其他类
- 更符合面向对象设计原则（组合优于继承）
- 线程池等高级功能只能接受Runnable或Callable

### 示例

```java
public class MultiThreadExample {
    public static void main(String[] args) {
        // 创建并启动5个线程
        for (int i = 1; i <= 5; i++) {
            new Thread(new Task(i), "Thread-" + i).start();
        }
        System.out.println("所有线程已启动，主线程继续执行...");
    }
}

class Task implements Runnable {
    private final int taskId;
    
    public Task(int id) {
        this.taskId = id;
    }
    
    @Override
    public void run() {
        System.out.println(Thread.currentThread().getName() + " 开始执行任务" + taskId);
        try {
            // 模拟任务执行时间
            Thread.sleep((long)(Math.random() * 2000));
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
        }
        System.out.println(Thread.currentThread().getName() + " 完成任务" + taskId);
    }
}
```

### Thread的join方法

`join()`方法用于**等待该线程终止**。调用某线程的join()方法后，当前线程会被阻塞，直到目标线程执行完毕。

==join()方法变体：==

- `join()`: 无限期等待，直到线程终止
- `join(long millis)`: 最多等待millis毫秒
- `join(long millis, int nanos)`: 最多等待millis毫秒加nanos纳秒

==join()使用场景：==

- 需要等待多个线程全部完成后才能继续执行的场景
- 线程之间有依赖关系时
- 收集多个线程的执行结果

==示例==

并行下载多个文件后合并

```java
public class FileDownloader {
    public static void main(String[] args) {
        String[] fileUrls = {
            "http://example.com/file1.zip",
            "http://example.com/file2.zip",
            "http://example.com/file3.zip"
        };
        
        Thread[] downloadThreads = new Thread[fileUrls.length];
        
        // 创建并启动下载线程
        for (int i = 0; i < fileUrls.length; i++) {
            final String url = fileUrls[i];
            downloadThreads[i] = new Thread(() -> {
                System.out.println("开始下载: " + url);
                // 模拟下载过程
                try {
                    Thread.sleep(2000 + (long)(Math.random() * 3000));
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                }
                System.out.println("下载完成: " + url);
            });
            downloadThreads[i].start();
        }
        
        // 等待所有下载完成
        for (Thread thread : downloadThreads) {
            try {
                thread.join();
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
            }
        }
        
        System.out.println("所有文件下载完成，开始合并...");
        // 合并文件的逻辑...
    }
}
```



## Runnable接口

==概念==

`Runnable` 接口是 Java 中用于创建线程任务的一个基础接口，位于 `java.lang` 包下。该接口中只有一个抽象方法 `run()`，其定义如下：

```java
@FunctionalInterface
public interface Runnable {
    public abstract void run();
}
```

任何实现了 `Runnable` 接口的类都需要实现 `run()` 方法，该方法中定义了线程要执行的任务。

==特点==

- **无返回值**：`run()` 方法没有返回值，即不能将任务执行的结果返回给调用者。
- **设计简单**：只包含一个方法，结构简单，适合用于执行一些不需要返回结果的任务。

==经典用法==

通常会将实现了 `Runnable` 接口的类的实例传递给 `Thread` 类的构造函数，然后调用 `Thread` 的 `start()` 方法来启动线程。以下是一个示例：

```java
class MyRunnable implements Runnable {
    @Override
    public void run() {
        for (int i = 0; i < 5; i++) {
            System.out.println(Thread.currentThread().getName() + " is running: " + i);
            try {
                Thread.sleep(100);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }
}

public class RunnableExample {
    public static void main(String[] args) {
        MyRunnable myRunnable = new MyRunnable();
        Thread thread = new Thread(myRunnable);
        thread.start();
    }
}
```

在这个例子中，`MyRunnable` 类实现了 `Runnable` 接口，在 `run()` 方法中定义了线程要执行的任务。在 `main` 方法中，创建了 `MyRunnable` 的实例，并将其传递给 `Thread` 类的构造函数，最后调用 `start()` 方法启动线程。

## Callable接口

==概念==

`Callable` 接口也是 Java 中用于创建线程任务的接口，位于 `java.util.concurrent` 包下。它与 `Runnable` 接口类似，但 `Callable` 接口中的 `call()` 方法可以返回一个结果，并且可以抛出异常。其定义如下：

```java
@FunctionalInterface
public interface Callable<V> {
    V call() throws Exception;
}
```

其中，`V` 是返回值的类型。

==特点==

- **有返回值**：`call()` 方法可以返回一个结果，通过泛型指定返回值的类型。
- **可抛出异常**：`call()` 方法可以抛出异常，便于在任务执行过程中处理异常情况。

==经典用法==

通常需要将 `Callable` 接口的实现类实例提交给 `ExecutorService` 来执行，通过 `Future` 对象获取任务的执行结果。以下是一个示例：

```java
import java.util.concurrent.*;

class MyCallable implements Callable<Integer> {
    @Override
    public Integer call() throws Exception {
        int sum = 0;
        for (int i = 1; i <= 10; i++) {
            sum += i;
        }
        return sum;
    }
}

public class CallableExample {
    public static void main(String[] args) {
        ExecutorService executor = Executors.newSingleThreadExecutor();
        MyCallable myCallable = new MyCallable();
        Future<Integer> future = executor.submit(myCallable);

        try {
            Integer result = future.get();
            System.out.println("The result is: " + result);
        } catch (InterruptedException | ExecutionException e) {
            e.printStackTrace();
        } finally {
            executor.shutdown();
        }
    }
}
```

在这个例子中，`MyCallable` 类实现了 `Callable` 接口，在 `call()` 方法中计算 1 到 10 的整数之和并返回结果。在 `main` 方法中，创建了一个单线程的线程池 `ExecutorService`，将 `MyCallable` 的实例提交给线程池执行，通过 `Future` 对象获取任务的执行结果。最后，关闭线程池。

## 线程池ThreadPoolExcecuter

 ==介绍==

`ThreadPoolExecutor` 是 Java 中用于创建和管理线程池的核心类，位于 `java.util.concurrent` 包下。线程池可以预先创建一定数量的线程，当有任务提交时，从线程池中获取线程来执行任务，任务执行完毕后线程不会销毁，而是返回线程池等待下一个任务。这样可以避免频繁创建和销毁线程带来的性能开销，提高系统的性能和稳定性。

==构造函数参数设置==

`ThreadPoolExecutor` 有多个构造函数，其中最常用的构造函数有 7 个参数，其定义如下：

```java
public ThreadPoolExecutor(int corePoolSize,
                          int maximumPoolSize,
                          long keepAliveTime,
                          TimeUnit unit,
                          BlockingQueue<Runnable> workQueue,
                          ThreadFactory threadFactory,
                          RejectedExecutionHandler handler)
```



- **`corePoolSize`**：核心线程数。线程池在初始化时会创建 `corePoolSize` 个线程，当有新任务提交时，如果线程池中的线程数量小于 `corePoolSize`，则会创建新的线程来执行任务。
- **`maximumPoolSize`**：最大线程数。线程池允许的最大线程数量，当任务队列已满且线程池中的线程数量小于 `maximumPoolSize` 时，会创建新的线程来执行任务。
- **`keepAliveTime`**：线程空闲时间。当线程池中的线程数量超过 `corePoolSize` 时，多余的空闲线程在经过 `keepAliveTime` 时间后会被销毁。
- **`unit`**：`keepAliveTime` 的时间单位，例如 `TimeUnit.SECONDS` 表示秒。
- **`workQueue`**：任务队列。用于存储等待执行的任务，当线程池中的线程都在执行任务时，新提交的任务会被放入任务队列中。常见的任务队列有 `ArrayBlockingQueue`、`LinkedBlockingQueue`、`SynchronousQueue` 等。
- **`threadFactory`**：线程工厂。用于创建线程，通过线程工厂可以自定义线程的名称、优先级等属性。
- **`handler`**：拒绝策略。当任务队列已满且线程池中的线程数量达到 `maximumPoolSize` 时，新提交的任务会被拒绝，此时会调用拒绝策略来处理被拒绝的任务。常见的拒绝策略有 `AbortPolicy`、`CallerRunsPolicy`、`DiscardPolicy`、`DiscardOldestPolicy` 等。

### 常用的几种创建线程池的方式

- **固定大小线程池**：

```java
ExecutorService fixedThreadPool = Executors.newFixedThreadPool(5);
```

创建一个固定大小为 5 的线程池，线程池中的线程数量始终保持为 5。

- **单线程线程池**：

```java
ExecutorService singleThreadExecutor = Executors.newSingleThreadExecutor();
```



创建一个只有一个线程的线程池，所有任务会按顺序依次执行。



- **缓存线程池**：

```java
ExecutorService cachedThreadPool = Executors.newCachedThreadPool();
```

创建一个可缓存的线程池，线程池中的线程数量会根据任务的数量动态调整。

不过，从 Java 7 开始，不推荐使用 `Executors` 工具类创建线程池，因为它可能会导致一些潜在的问题，如 `newFixedThreadPool` 和 `newSingleThreadExecutor` 使用的是无界队列，可能会导致内存溢出；`newCachedThreadPool` 可能会创建大量的线程，导致系统资源耗尽。建议直接使用 `ThreadPoolExecutor` 来创建线程池

直接使用 `ThreadPoolExecutor` 创建线程池

```java
import java.util.concurrent.*;

public class ThreadPoolExample {
    public static void main(String[] args) {
        ThreadPoolExecutor executor = new ThreadPoolExecutor(
                2, // 核心线程数
                5, // 最大线程数
                60, // 线程空闲时间
                TimeUnit.SECONDS, // 时间单位
                new LinkedBlockingQueue<>(10), // 任务队列
                Executors.defaultThreadFactory(), // 线程工厂
                new ThreadPoolExecutor.AbortPolicy() // 拒绝策略
        );
    }
}
```

4. 与 `Runnable` 和 `Callable` 的结合使用

### 与 `Runnable` 结合使用

`Runnable` 接口中的 `run()` 方法没有返回值，适合用于执行一些不需要返回结果的任务。可以使用 `execute()` 方法将 `Runnable` 任务提交给线程池执行。

```java
import java.util.concurrent.*;

class MyRunnable implements Runnable {
    @Override
    public void run() {
        System.out.println(Thread.currentThread().getName() + " is running.");
    }
}

public class ThreadPoolRunnableExample {
    public static void main(String[] args) {
        ThreadPoolExecutor executor = new ThreadPoolExecutor(
                2,
                5,
                60,
                TimeUnit.SECONDS,
                new LinkedBlockingQueue<>(10)
        );

        MyRunnable myRunnable = new MyRunnable();
        executor.execute(myRunnable);

        executor.shutdown();
    }
}
```

### 与 `Callable` 结合使用

`Callable` 接口中的 `call()` 方法可以返回一个结果，适合用于执行需要返回结果的任务。可以使用 `submit()` 方法将 `Callable` 任务提交给线程池执行，并通过 `Future` 对象获取任务的执行结果。

```java
import java.util.concurrent.*;

class MyCallable implements Callable<Integer> {
    @Override
    public Integer call() throws Exception {
        int sum = 0;
        for (int i = 1; i <= 10; i++) {
            sum += i;
        }
        return sum;
    }
}

public class ThreadPoolCallableExample {
    public static void main(String[] args) {
        ThreadPoolExecutor executor = new ThreadPoolExecutor(
                2,
                5,
                60,
                TimeUnit.SECONDS,
                new LinkedBlockingQueue<>(10)
        );

        MyCallable myCallable = new MyCallable();
        Future<Integer> future = executor.submit(myCallable);

        try {
            Integer result = future.get();
            System.out.println("The result is: " + result);
        } catch (InterruptedException | ExecutionException e) {
            e.printStackTrace();
        }

        executor.shutdown();
    }
}
```



在上述代码中，`MyCallable` 类实现了 `Callable` 接口，在 `call()` 方法中计算 1 到 10 的整数之和并返回结果。在 `main` 方法中，将 `MyCallable` 的实例提交给线程池执行，通过 `Future` 对象获取任务的执行结果。最后，关闭线程池。

### 线程池实例



## 多线程经典实际应用举例



# kafka



# ES

## 倒排索引的结构与原理分词（Term）

这种情况下，如果要想快速地检索到目标文章，则必须将文章分割成一个个关键字，再将关键词与文章建立索引关系。Elasticsearch里分词关键字称作term。

例：i am happy用elasticsearch标准分词器切分的关键字结果是i,am,happy

倒排列表（posting list）
根据切分好的关键字，将关键字与包含该关键字的文档进行关联，组成的结构称为倒排列表，即倒排索引。

如文档doc1包含内容i am happy，文档doc2包含内容i am your father，拆解成的倒排列表如下：


倒排索引主要由两个部分组成：

- **词典（Dictionary）**：存储文档中所有唯一的词（term）。
- **倒排列表（Posting List）**：每个词对应一个列表，包含所有包含该词的文档 ID，以及其他相关信息，如词频（TF）和文档频率（DF）。

![image-20250312215242681](C:\Users\Brantu\AppData\Roaming\Typora\typora-user-images\image-20250312215242681.png)

## 倒排索引的工作流程

文档分析：将文档中的文本分解为词项（tokens），并进行标准化处理（如小写化、去除停用词）。
构建索引：为每个词项在词典中创建条目，并将对应的文档 ID 添加到倒排列表中。
搜索请求：当接收到搜索请求时，Elasticsearch 将查询的词项映射到倒排索引，快速找到相关文档。

## 基本类型

 **字符串类型（Text 和 Keyword）**
Text：

用于分析的文本字段，适合全文搜索。
存储时会被分词（tokenization），便于查找。
适用于长文本，如文章、描述等。
示例：

```java
"description": {
  "type": "text"
}
```

**Keyword：**

不进行分析的字符串字段，适合精确匹配。
通常用于 ID、标签、类别等需要精确查询的字段。
示例：

```
"category": {
  "type": "keyword"
}
```


 **数字类型（Integer, Float, Double, etc.）**
**Integer：**

整数类型，适用于整数字段。
示例：

```
"age": {
  "type": "integer"
}
```

**Float、Double：**

浮点数类型，适合存储小数。
示例：

```
"price": {
  "type": "float"
}
```


**布尔类型（Boolean）**
Boolean：

只存储 true 或 false 值。
示例：

```
"is_active": {
  "type": "boolean"
}
```

**期类型**
Date：

用于存储日期和时间，支持多种日期格式。
示例：

```
"created_at": {
  "type": "date",
  "format": "yyyy-MM-dd'T'HH:mm:ss.SSSZ"
}
```

**对象和嵌套类型**
**对象类型（Object）**
Object：

用于存储 JSON 对象，字段可以嵌套。
适合存储复杂的数据结构。
示例：

```java
"address": {
  "type": "object",
  "properties": {
    "city": { "type": "keyword" },
    "zip": { "type": "integer" }
  }
}
```

**嵌套类型（Nested）**
Nested：

专门用于处理数组中的对象，确保在查询时保持对象之间的关系。
避免在传统对象类型中因扁平化导致的数据混乱。
示例：

```
"comments": {
  "type": "nested",
  "properties": {
    "user": { "type": "keyword" },
    "message": { "type": "text" }
  }
}
```


以下是一个完整的映射示例，展示了多种字段类型的结合使用：

```java
PUT /my_index
{
  "mappings": {
    "properties": {
      "title": {
        "type": "text"
      },
      "author": {
        "type": "keyword"
      },
      "published_date": {
        "type": "date"
      },
      "price": {
        "type": "float"
      },
      "tags": {
        "type": "keyword"
      },
      "comments": {
        "type": "nested",
        "properties": {
          "user": { "type": "keyword" },
          "message": { "type": "text" }
        }
      },
      "location": {
        "type": "geo_point"
      }
    }
  }
}
```

## ES的理解

【1】**index索引，在es中代表着数据库**

**库里有一定的mapping映射，它是对索引库中文档的约束，创建索引时同步构建mapping映射**

常见的mapping

type：字段数据类型，常见的简单类型有：
字符串：text（可分词的文本）、keyword（精确值，例如：品牌、国家、ip地址）
数值：long、integer、short、byte、double、float、
布尔：boolean
日期：date
对象：object
index：是否创建索引，默认为true
analyzer：使用哪种分词器，ik_max_word和ik_smart模式。**ik_max_word:** 会将文本做最细粒度的拆分； **ik_smart**会做最粗粒度的拆分

properties：该字段的子段

【2】对于修改索引，因此索引库**一旦创建，无法修改mapping，因为会触发倒排索引重构**。虽然无法修改mapping中已有的字段，但是却允许添加新的字段到mapping中，因为不会对倒排索引产生影响。

【3】es的存储方式是倒排索引，在插入文档的时候就会形成，内部保存的是分词在文档中的位置（？）

【4】restful格调用，**在hit中会看到命中的文档结果**



term与dictionary

## java实例与es中的映射

```java
public class Employee {
 
  private String email;
  private String firstName;
  private String lastName;
  private EmployeeInfo info;
  private Date joinDate;
 
}
```

```java
private class EmployeeInfo {
 
  private String bio; // 性格
  private Integer age;
  private String[] interests; // 兴趣爱好
 
}
```

```json
{
    "email":  "zhupei@tianfang1314.cn",
    "first_name": "pei",
    "last_name": "zhu",
    "info": {
    "bio": "curious and modest",
    "age": 25,
    "interests": [ "bike", "run" ]
    },
    "join_date": "2017/11/07"
}
```

## ES的语法

查询集群有哪些索引

```java
GET /_cat/indices?v
```

### 索引库

**创建索引库**

```java
PUT /索引库名称
{
  "mappings": {
    "properties": {
      "字段名":{
        "type": "text",
        "analyzer": "ik_smart"
      },
      "字段名2":{
        "type": "keyword",
        "index": "false"
      },
      "字段名3":{
        "properties": {
          "子字段": {
            "type": "keyword"
          }
        }
      },
      // ...略
    }
  }
}

```

eg:

```java
PUT /my_index
{
  "mappings": {
    "properties": {
      "title": {
        "type": "text"
      },
      "author": {
        "type": "keyword"
      },
      "published_date": {
        "type": "date"
      },
      "price": {
        "type": "float"
      },
      "tags": {
        "type": "keyword"
      },
      "comments": {
        "type": "nested",
        "properties": {
          "user": { "type": "keyword" },
          "message": { "type": "text" }
        }
      },
      "location": {
        "type": "geo_point"
      }
    }
  }
}

```

**获取索引库**

```
GET /索引库名
```

![image-20250313172329849](C:\Users\Brantu\AppData\Roaming\Typora\typora-user-images\image-20250313172329849.png)

**删除索引库**

```java
DELETE /索引库名
```

**修改索引库**

```java
PUT /索引库名/_mapping
{
  "properties": {
    "新字段名":{
      "type": "integer"
    }
  }
}

```

### 针对文档使用

#### **新增文档**

```json
POST /索引库名/_doc(type)/文档id
{
    "字段1": "值1",
    "字段2": "值2",
    "字段3": {
        "子属性1": "值3",
        "子属性2": "值4"
    },
    // ...
}

PUT /shoes/product/1
{
    "name" : "NB 鞋子",
    "desc" :  "特别好的鞋子",
    "price" :  530,
    "producer" :  "NB producer",
    "tags": [ "实用", "美观" ]
}

```

![image-20250313173310307](C:\Users\Brantu\AppData\Roaming\Typora\typora-user-images\image-20250313173310307.png)

#### **查询文档**

**普通查询**

```
GET /customer/_doc/1
```

**批量查询**

`match_all`表示查询所有的数据，sort即按照什么字段排序

```json
GET /bank/_search
{
  "query": { "match_all": {} },
  "sort": [
    { "account_number": "asc" }
  ]
}
```

**分页查询**

本质上就是from和size两个字段

```json
GET /bank/_search
{
  "query": { "match_all": {} },
  "sort": [
    { "account_number": "asc" }
  ],
  "from": 10,
  "size": 10
}
```

**指定字段查询：match**

如果要在字段中搜索特定字词，可以使用`match`; 如下语句将查询address 字段中包含 mill 或者 lane的数据

```json
GET /bank/_search
{
  "query": { "match": { "address": "mill lane" } }
}
```

![image-20250313175718282](C:\Users\Brantu\AppData\Roaming\Typora\typora-user-images\image-20250313175718282.png)

**查询段落匹配：match_phrase**

如果我们希望查询的条件是 address字段中包含 “mill lane”，则可以使用`match_phrase`

```json
GET /bank/_search
{
  "query": { "match_phrase": { "address": "mill lane" } }
}
```

**多条件查询: bool**

must：文档必须匹配的条件，类似于 SQL 的 AND。例如：
field1 必须包含 value1。
field2 必须在 [10, 20] 范围内。

should：非必须条件，匹配的条件越多，相关性得分（*score）越高。至少有一个条件匹配时，文档会更相关。
field3 或 field4 中匹配一个即可加分。

must_not：文档不能包含的条件，类似于 SQL 的 NOT。
排除 field5 等于 excluded_value 的文档。

filter：过滤条件，类似于 must，但不影响相关性评分（score），性能较高。
field6 必须为 filtered_value。

```json
GET your_index/_search
{
  "query": {
    "bool": {
      "must": [
        {
          "match": {
            "field1": "value1"
          }
        },
        {
          "range": {
            "field2": {
              "gte": 10,
              "lte": 20
            }
          }
        }
      ],
      "should": [
        {
          "term": {
            "field3": "optional_value1"
          }
        },
        {
          "term": {
            "field4": "optional_value2"
          }
        }
      ],
      "must_not": [
        {
          "term": {
            "field5": "excluded_value"
          }
        }
      ],
      "filter": [
        {
          "term": {
            "field6": "filtered_value"
          }
        }
      ]
    }
  }
}
```



## 组件RestHighLevelClient

`RestHighLevelClient` 是 Elasticsearch 提供的高级 REST 客户端，它基于低级别 REST 客户端构建，提供了更便捷的 API 来与 Elasticsearch 进行交互。以下将详细介绍 `RestHighLevelClient` 的用法，涵盖初始化、常见操作（如索引操作、文档操作、查询操作）等方面。

### 初始化 `RestHighLevelClient`

首先，你需要在项目中添加 Elasticsearch 客户端的依赖。以 Maven 为例，在 `pom.xml` 中添加以下依赖：

```xml
<dependency>
    <groupId>org.elasticsearch.client</groupId>
    <artifactId>elasticsearch-rest-high-level-client</artifactId>
    <version>7.17.3</version>
</dependency>
<dependency>
    <groupId>org.elasticsearch</groupId>
    <artifactId>elasticsearch</artifactId>
    <version>7.17.3</version>
</dependency>
```

然后，使用以下代码初始化 `RestHighLevelClient`：

```java
import org.elasticsearch.client.RestClient;
import org.elasticsearch.client.RestHighLevelClient;

public class ElasticsearchClientFactory {
    public static RestHighLevelClient createClient() {
        RestHighLevelClient client = new RestHighLevelClient(
                RestClient.builder(
                        new org.apache.http.HttpHost("localhost", 9200, "http")));
        return client;
    }

    public static void closeClient(RestHighLevelClient client) {
        try {
            client.close();
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}
```

上述代码创建了一个连接到本地 Elasticsearch 服务（运行在 `localhost:9200`）的 `RestHighLevelClient` 实例。

### 索引操作

#### 创建索引

```java
import org.elasticsearch.action.admin.indices.create.CreateIndexRequest;
import org.elasticsearch.action.admin.indices.create.CreateIndexResponse;
import org.elasticsearch.client.RequestOptions;
import org.elasticsearch.client.RestHighLevelClient;
import java.io.IOException;

public class IndexCreationExample {
    public static void main(String[] args) {
        RestHighLevelClient client = ElasticsearchClientFactory.createClient();
        CreateIndexRequest request = new CreateIndexRequest("my_index");
        try {
            CreateIndexResponse response = client.indices().create(request, RequestOptions.DEFAULT);
            boolean acknowledged = response.isAcknowledged();
            if (acknowledged) {
                System.out.println("Index created successfully");
            } else {
                System.out.println("Failed to create index");
            }
        } catch (IOException e) {
            e.printStackTrace();
        } finally {
            ElasticsearchClientFactory.closeClient(client);
        }
    }
}
```

#### 删除索引

```java
import org.elasticsearch.action.admin.indices.delete.DeleteIndexRequest;
import org.elasticsearch.action.support.master.AcknowledgedResponse;
import org.elasticsearch.client.RequestOptions;
import org.elasticsearch.client.RestHighLevelClient;
import java.io.IOException;

public class IndexDeletionExample {
    public static void main(String[] args) {
        RestHighLevelClient client = ElasticsearchClientFactory.createClient();
        DeleteIndexRequest request = new DeleteIndexRequest("my_index");
        try {
            AcknowledgedResponse response = client.indices().delete(request, RequestOptions.DEFAULT);
            boolean acknowledged = response.isAcknowledged();
            if (acknowledged) {
                System.out.println("Index deleted successfully");
            } else {
                System.out.println("Failed to delete index");
            }
        } catch (IOException e) {
            e.printStackTrace();
        } finally {
            ElasticsearchClientFactory.closeClient(client);
        }
    }
}
```

### 文档操作

####  插入文档

```java
import org.elasticsearch.action.index.IndexRequest;
import org.elasticsearch.action.index.IndexResponse;
import org.elasticsearch.client.RequestOptions;
import org.elasticsearch.client.RestHighLevelClient;
import org.elasticsearch.common.xcontent.XContentType;
import java.io.IOException;

public class DocumentInsertionExample {
    public static void main(String[] args) {
        RestHighLevelClient client = ElasticsearchClientFactory.createClient();
        String jsonString = "{\"name\":\"John Doe\",\"age\":30}";
        IndexRequest request = new IndexRequest("my_index")
               .id("1")
               .source(jsonString, XContentType.JSON);
        try {
            IndexResponse response = client.index(request, RequestOptions.DEFAULT);
            System.out.println("Document inserted with ID: " + response.getId());
        } catch (IOException e) {
            e.printStackTrace();
        } finally {
            ElasticsearchClientFactory.closeClient(client);
        }
    }
}
```

#### 获取文档

```java
import org.elasticsearch.action.get.GetRequest;
import org.elasticsearch.action.get.GetResponse;
import org.elasticsearch.client.RequestOptions;
import org.elasticsearch.client.RestHighLevelClient;
import java.io.IOException;

public class DocumentRetrievalExample {
    public static void main(String[] args) {
        RestHighLevelClient client = ElasticsearchClientFactory.createClient();
        GetRequest request = new GetRequest("my_index", "1");
        try {
            GetResponse response = client.get(request, RequestOptions.DEFAULT);
            if (response.isExists()) {
                String sourceAsString = response.getSourceAsString();
                System.out.println("Document content: " + sourceAsString);
            } else {
                System.out.println("Document not found");
            }
        } catch (IOException e) {
            e.printStackTrace();
        } finally {
            ElasticsearchClientFactory.closeClient(client);
        }
    }
}
```

#### 更新文档

```java
import org.elasticsearch.action.update.UpdateRequest;
import org.elasticsearch.action.update.UpdateResponse;
import org.elasticsearch.client.RequestOptions;
import org.elasticsearch.client.RestHighLevelClient;
import org.elasticsearch.common.xcontent.XContentType;
import java.io.IOException;

public class DocumentUpdateExample {
    public static void main(String[] args) {
        RestHighLevelClient client = ElasticsearchClientFactory.createClient();
        String jsonString = "{\"age\":31}";
        UpdateRequest request = new UpdateRequest("my_index", "1")
               .doc(jsonString, XContentType.JSON);
        try {
            UpdateResponse response = client.update(request, RequestOptions.DEFAULT);
            System.out.println("Document updated successfully");
        } catch (IOException e) {
            e.printStackTrace();
        } finally {
            ElasticsearchClientFactory.closeClient(client);
        }
    }
}
```

#### 删除文档

```java
import org.elasticsearch.action.delete.DeleteRequest;
import org.elasticsearch.action.delete.DeleteResponse;
import org.elasticsearch.client.RequestOptions;
import org.elasticsearch.client.RestHighLevelClient;
import java.io.IOException;

public class DocumentDeletionExample {
    public static void main(String[] args) {
        RestHighLevelClient client = ElasticsearchClientFactory.createClient();
        DeleteRequest request = new DeleteRequest("my_index", "1");
        try {
            DeleteResponse response = client.delete(request, RequestOptions.DEFAULT);
            System.out.println("Document deleted successfully");
        } catch (IOException e) {
            e.printStackTrace();
        } finally {
            ElasticsearchClientFactory.closeClient(client);
        }
    }
}
```

### 4. 查询操作

#### 简单查询

```java
import org.elasticsearch.action.search.SearchRequest;
import org.elasticsearch.action.search.SearchResponse;
import org.elasticsearch.client.RequestOptions;
import org.elasticsearch.client.RestHighLevelClient;
import org.elasticsearch.index.query.QueryBuilders;
import org.elasticsearch.search.builder.SearchSourceBuilder;
import java.io.IOException;

public class SimpleSearchExample {
    public static void main(String[] args) {
        RestHighLevelClient client = ElasticsearchClientFactory.createClient();
        SearchRequest searchRequest = new SearchRequest("my_index");
        SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();
        searchSourceBuilder.query(QueryBuilders.matchQuery("name", "John Doe"));
        searchRequest.source(searchSourceBuilder);
        try {
            SearchResponse searchResponse = client.search(searchRequest, RequestOptions.DEFAULT);
            System.out.println("Search hits: " + searchResponse.getHits().getTotalHits().value);
        } catch (IOException e) {
            e.printStackTrace();
        } finally {
            ElasticsearchClientFactory.closeClient(client);
        }
    }
}
```

### 5. 注意事项

- **异常处理**：在使用 `RestHighLevelClient` 进行操作时，要对可能出现的 `IOException` 等异常进行处理，避免程序崩溃。
- **资源管理**：使用完 `RestHighLevelClient` 后，要调用 `close()` 方法关闭客户端，释放资源。
- **版本兼容性**：确保使用的 Elasticsearch 客户端版本与 Elasticsearch 服务版本兼容，避免出现兼容性问题。



通过以上示例，你可以了解到 `RestHighLevelClient` 在 Elasticsearch 操作中的基本用法，包括索引操作、文档操作和查询操作等。



# Xshell命令操作【日志查看，部署】

## ps -ef | grep nginx

获取所有ng信息，命令用于报告当前系统的进程状态。

## 查看linux内存情况

### `free` 命令

`free` 命令用于显示系统内存的使用情况，包括物理内存、交换内存（swap）的使用情况。

```bash
free -h
```

- -h` 选项：以人类可读的格式显示内存大小，例如使用 GB、MB 等单位。

### `vmstat` 命令

`vmstat` 可以报告关于内核线程、虚拟内存、磁盘、陷阱和 CPU 活动的统计信息。

```bash
vmstat 1 5
```

- 第一个参数 `1` 表示每隔 1 秒刷新一次统计信息。
- 第二个参数 `5` 表示总共刷新 5 次。

### `top` 命令

`top` 是一个动态实时监控进程活动的工具，它可以显示系统中各个进程的资源占用情况，包括 CPU、内存等

进入 `top` 界面后，你可以看到以下重要信息：

- **系统信息**：显示系统的整体状态，如当前时间、系统运行时间、登录用户数、系统负载等。
- **进程信息**：列出当前系统中占用资源较多的进程，包括进程 ID（PID）、用户（USER）、CPU 使用率（% CPU）、内存使用率（% MEM）等。

在 `top` 界面中，你还可以使用一些快捷键进行操作：

- q`：退出 `top` 界面。
- `M`：按照内存使用率排序。
- `P`：按照 CPU 使用率排序。

## cd相关

工程基本部署在/data/server下

日志记录在log目录进对应的工程下：

cd  /data/log/项目名称/

cd .. 

cd ./data

1. **cd**：不带参数时，返回用户的主目录。例如：

   ```
   bashcd
   ```

   这会将当前目录更改为用户的主目录。

2. **cd 目录路径**：将当前工作目录更改为指定的目录路径。例如：

   ```
   bashcd /home/user/documents
   ```

   这会将当前目录更改为 `/home/user/documents`。

3. **cd ~** 或 **cd**：这两种方式都可以返回用户的主目录。例如：

   ```
   bashcd ~
   ```

   或者简单地：

   ```
   bashcd
   ```

4. **cd -**：切换到上次所在的目录。例如，如果你先切换到 `/home/user/documents`，然后切换到其他目录，再执行 `cd -`，就会回到 `/home/user/documents`。

5. **cd ..**：返回上一级目录。例如：

   ```
   bashcd ..
   ```

   这会将当前目录更改为上级目录。

6. **cd ../..**：返回上两级目录，依此类推，可以使用多个 `..` 来向上跳转多级目录。

7. **cd /**：返回到根目录。例如：

   ```
   bashcd /
   ```

8. **cd ~username**：切换到指定用户的主目录。例如：

   ```
   bashcd ~john
   ```

   这会将当前目录更改为用户 `john` 的主目录。

这些是 `cd` 命令的一些常见用法和相关命令。`cd` 是命令行中常用的基本命令，用来在不同目录之间切换和操作文件系统。

## tail -f  xxx.log 实时查看

### 解释：

1. **`tail` 命令**：`tail` 是一个常用的命令行工具，用于显示文件末尾的内容。
2. **`-f` 参数**：`-f` 参数代表 `follow`，即跟随文件内容的变化。在实时监控文件时，`tail -f` 会持续显示文件的最新内容，并且不会退出命令，而是继续等待新的数据。
3. **`-`n 参数**：参数告诉 `tail` 命令显示文件的最后100行。
4. **`xxx.log`**：这是文件名，通常是你希望监控的日志文件名或其他文本文件名。

### 使用场景：

- **日志监控**：最常见的用途是实时监控日志文件的变化。例如，你可以在终端运行 `tail -f error.log` 来实时查看 `error.log` 文件中新添加的错误信息。
- **调试和分析**：开发人员和系统管理员可以使用 `tail -f` 命令来实时查看和分析正在发生的事情，如程序输出或系统日志。
- **持续更新的输出**：在需要持续获取某个文件尾部变化的情况下，`tail -f` 提供了一种简单有效的方式来达到这个目的，而不需要反复手动执行命令。

总之，`tail -f xxx.log` 命令可以帮助你实时查看文件内容的变化，特别适合于需要跟踪日志文件的情况。

## grep 'xxx' stdout.log

抓取带xxx内容的log日志

## curl发送请求的

`curl` 

是一个命令行工具和库，用于传输数据，支持多种协议，包括 HTTP、HTTPS、FTP 等。它在 Unix、Linux 和类 Unix 系统上广泛使用，并且有 Windows 版本。

1. **下载文件：** 使用 `curl` 可以通过 HTTP、HTTPS、FTP 等协议下载文件。例如：

   ```
   bashcurl -O https://example.com/file.zip
   ```

   这将从指定 URL 下载文件并保存在当前目录。

2. **发送请求：** `curl` 可以用来发送 HTTP 请求并获取响应。这对于测试 Web 服务的响应或自动化脚本中的数据传输非常有用。例如：

   ```
   bashcurl -X GET https://api.example.com/data
   ```

   或者：

   ```
   bashcurl -X POST -d '{"key": "value"}' -H "Content-Type: application/json" https://api.example.com/endpoint
   ```

   这些命令分别发送 GET 和 POST 请求，获取或发送数据到指定的 API 端点。

3. **处理 REST API：** 开发者经常使用 `curl` 来与 RESTful API 进行交互。它可以模拟各种 HTTP 请求方法（GET、POST、PUT、DELETE 等），并支持自定义头部信息和请求体数据。

4. **上传文件：** 除了下载，`curl` 也支持上传文件到远程服务器，使用 `-T` 参数。例如：

   ```
   bashcurl -T uploadfile.txt ftp://ftp.example.com/upload/
   ```

   这将上传本地的 `uploadfile.txt` 文件到 FTP 服务器上的指定目录。

5. **测试和调试：** `curl` 在开发和调试过程中是一个强大的工具，可以快速验证 Web 服务是否正常工作，或者用来获取远程服务器的响应头和内容，检查 HTTP 状态码等。

6. **支持代理：** `curl` 支持使用代理服务器发送和接收数据，这对于访问需要通过代理的网络非常有用。

7. **文件传输支持：** `curl` 支持断点续传、文件断点续传等高级功能，可以更安全地下载和上传大文件。

总之，`curl` 是一个功能强大的命令行工具，适用于多种网络传输需求，是系统管理员、开发人员和测试人员经常使用的工具之一。

## cat stdout.2024-07*.log | grep '学生' --color

- `cat` 命令用于连接文件并打印到标准输出。
- `stdout.2024-07*.log` 使用了通配符 `*`，表示所有以 `stdout.2024-07` 开头且以 `.log` 结尾的文件名。这里假设 `2024-07*` 是匹配到的文件名部分，可能包括多个文件，如 `stdout.2024-07-01.log`, `stdout.2024-07-15.log` 等。
- `cat stdout.2024-07*.log` 将会把所有符合条件的日志文件内容输出到标准输出。
- **`grep '学生' --color`**：
  - `grep` 是一个强大的文本搜索工具，用于在文件或标准输入中查找匹配某个模式的行。
  - `'学生'` 是要搜索的模式，即需要在日志文件中查找包含 `学生` 关键词的行。
  - `--color` 参数会使匹配的文本以颜色高亮显示，这可以提高可读性，但在某些环境中可能需要适当配置才能生效

`grep` 命令有很多选项可以用来进行更复杂的搜索，如 `-i` 忽略大小写，`-v` 反向查找不匹配的行，`-E` 支持正则表达式等

## vim编辑命令

### 使用快捷键进行退出

1、按“Esc”键进入命令模式

当我们在vim编辑模式下输入完毕需要进行退出操作时，首先需要按下“Esc”键，将vim编辑器从插入模式或者替换模式切换到命令模式。

    ESC

2、输入“:wq”保存并退出

在命令模式下，输入“:wq”命令，表示保存并退出vim编辑器。

    :wq

3、输入“:q!”强制退出

当我们在未保存文件的情况下，需要强制退出vim编辑器时，可以在命令模式下输入“:q!”命令。

    :q!

### 使用菜单进行退出

1、按“Esc”键进入命令模式

同样需要进入命令模式，按下“Esc”键。

    ESC

2、输入“:w”保存

在命令模式下，输入“:w”命令，表示保存文件。

    :w

3、按下“Shift + Z + Z”退出

在命令模式下，按下“Shift + Z + Z”快捷键，表示保存并退出vim编辑器。

    Shift + Z + Z

### 使用vim的扩展命令进行退出

1、按“Esc”键进入命令模式

同样需要进入命令模式，按下“Esc”键。

    ESC

2、输入“:x”保存并退出

在命令模式下，输入“:x”命令，表示保存并退出vim编辑器。

    :x

3、输入“:wqa”保存全部并退出

在命令模式下，输入“:wqa”命令，表示保存全部并退出vim编辑器。

    :wqa

## 部署流程：

涉及的命令：

lsof -i：端口号 查看某个端口号所在的进程号

pwds 进程号 ： 获取该进程所在的文件路径

kill -9: 强制结束某个进程

rm 文件名：删除某个文件

rm -rf： 删除文件夹全部内容，且不经过删除确认

mkdir folder_name 

rz -be：进到某个目录下，将打好的tar包上传到指定位置

解压包相关：

tar -xvf    解压.tar

tar -xvzf  解压.tar.gz 或 .tgz 文件

启动用启动脚本，sh start.sh启动项目

杀死进程，删掉tar包，上传新的，解压运行







# 携程工作记录




















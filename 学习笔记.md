# 新入职准备工作

## Typora使用笔记

**视图展开**

文件 --》偏好设置 --》外观 --》 侧边栏 --》勾选侧边栏的大纲视图允许折叠和展开



**高亮快捷键**： == ==



**偏好设置优先使用相对路径**



**段落模板配置**



# 讯飞项目管理

##  运营系统

### **用户请求诊断**：

**功能介绍**：对用户搜索后的错误返回进行人工修正和诊断，提问理解或者语义拆分进行分析，展示服务端精排粗排重排结果，人工干预排序和打分

qa数据同时存在在运营系统和大数据爬虫平台：主要title、summary、content三部分【来源、置信度、召回数量、相关性、置信度】

【**1.**】大数据组通过kafka写，时政/国家新闻敏感数据【与业务场景有关】通过redis每日刷入更新

【**2.**】构造延迟队列解决数据完整性问题，qa数据实时落库，核对数据发现跨天数据缺失，基于redis的sorted set构造了延迟队列将跨天前10分钟的数据保存进行二次消费

**【3.**】异步批处理qa数据并落库，多线程+bacthinsert，saveList【mongo】

【**4.**】请求评测，分词重写，支持qa分析与编辑，请求诊断使用es读取服务端的分词结果+用jsonNode【前缀】解析结果搜索服务的重排精排高亮结果。 

```java
// 分词
objectMapper.readTree(jsonNode.at("/Msg/SegResult").asText())
        .at("/0/qu_response/qu_results").forEach(e -> {
            if (e.at("/seg_result/segMode").asInt() == 0L) {
                AtomicInteger idx = new AtomicInteger(1);
                e.at("/seg_result/words").forEach(word -> {
                    // noinspection unchecked
                    segList.add(new SegResultVO(
                            idx.getAndIncrement(),
                            word.at("/tag").asText(),
                            word.at("/weight").asDouble(),
                            word.at("/word").asText(),
                            objectMapper.convertValue(word.at("/synonyms"), ArrayList.class)
                    ));
                });
            }
        });
```

### **领域库管理**：

**功能介绍**：爬虫组爬取的网页信息经过数据解析后会进入设计好的13个领域库，科学医疗教育编程旅游等等，这些数据在milvus会形成向量库数据，运营系统需要有统一查看领域库数据，对数据提供编辑删除查询黑名单等功能，在流程中通过中间表维护回滚操作。单表千万~亿级别的查询，故障混滚保障。

**主流程：**

顺序：先milvius再manticoreSearch再mongo

**【一】**编辑与删除--主要在于修改title和summary

1.修改title+summary通过服务重新获取向量结果，创建两个中间表，一个记录完整的数据+更新前后的信息，一个维护主要的id title和状态【便于回查问题】

2.先修删除milvius再新增的方式更新

3.更具新增的调用manticoreSearch重新分词并更新【summary、content的lac和jieba分词】

4.更新mongo领域库次词条信息

5.成功删除记录表只维护标记表

过程中涉及调用其他服务，catch中如果出现任意的异常，则根据反序回滚

**【二】**查询与检索，嵌套线程池

在库的层级建立  List<Callable<Boolean>> callableList = new ArrayList<>();

**外层**一个List包启用多线程的Callable对象任务列表，每个对象都是查询不同的库

提交到线程池  futures.add(EXECUTOR.submit(callable));

**内层**

- 将`Future`对象转换为`CompletableFuture`，以便可以使用更强大的异步编程功能。
- 每个`CompletableFuture`在获取结果时设置了500毫秒的超时时间。如果超时或发生异常，返回`null`并记录错误日志。



List<Callable<IURLMongoInfoDownloadDto>> 

```java
private IURLMongoInfoDownloadDto getMongoInfo(String url){
        if (url==null) {
            return null;
        }
        List<Callable<IURLMongoInfoDownloadDto>> callableList = new ArrayList<>();
        Arrays.stream(ParseCollectionEnum.values()).forEach(ce -> {
            callableList.add(() -> doFindFromDb(url, ce));
        });

        try {
            List<Future<IURLMongoInfoDownloadDto>> futures = new ArrayList<>();
            for (Callable<IURLMongoInfoDownloadDto> callable : callableList) {
                futures.add(EXECUTOR.submit(callable));
            }
            List<CompletableFuture<IURLMongoInfoDownloadDto>> futureList = futures.stream()
                    .map(f -> CompletableFuture.supplyAsync(() -> {
                        try {
                            return f.get(500, TimeUnit.MILLISECONDS);
                        } catch (Exception e) {
                            log.error("[QueryParseResult result = f.get(1000, TimeUnit.MILLISECONDS)] future get err: ", e);
                            return null;
                        }
                    }))
                    .collect(Collectors.toList());
            CompletableFuture<Void> allFuturesResult = CompletableFuture.allOf(futureList.toArray(new CompletableFuture[0]));
            allFuturesResult.get();
            List<IURLMongoInfoDownloadDto> resultList = new ArrayList<>();
            futureList.forEach(f ->{
                try {
                    if(f.get() != null){
                        resultList.add(f.get());
                    }
                } catch (InterruptedException | ExecutionException e) {
                    log.error("获取 CompletableFuture 结果时出错: ", e);
                    // 在这里处理异常情况，例如添加默认值或者进行其他逻辑处理
                    resultList.add(null);
                }
            });

            if(CollectionUtils.isEmpty(resultList)){
                return null;
            }else {
                return resultList.stream().filter(Objects::nonNull).collect(Collectors.toList()).get(0);
            }
        }
        catch (Exception e) {
            log.error("doFindFromUrl err: ", e);
            return null;
        }
    }

    private IURLMongoInfoDownloadDto doFindFromDb(String url, ParseCollectionEnum ce){
        long id = MD5Utils.getMd5IdToLong(url);
        Query query = Query.query(Criteria.where("_id").is(id));
        IURLMongoInfoDownloadDto dto = mongoTemplateTwo.findOne(query, IURLMongoInfoDownloadDto.class, ce.getCollectionName());
        return dto;
    }
```

【三】懒加载式查询优化，url转id记录当前页的首尾id，灵活快速翻页

**疑问**

【1】**什么是milvius？什么是manticoreSearch**？

### 结果干预&离线召回

结果干预：请求诊断的详情中可以进行结果干预，同步到es

- **人工置顶**：将某些结果强制排在前面。
- **权重调整**：通过调整排序模型的权重，影响结果的排名。
- **过滤规则**：屏蔽某些不符合条件的结果。

离线召回的数据不可以人工干预排序结果，只对删除和是否启用多保留

![image-20230822102535339](E:\笔记\废弃日常材料z\image-20230822102535339.png)

**结合使用**

在实际搜索系统中，**结果干预**和**离线召回**通常是结合使用的：

1. **离线召回**负责从海量数据中筛选出高质量的候选集。
2. **在线排序**模型对候选集进行精细排序。
3. **结果干预**在最终展示阶段对排序结果进行调整，以满足业务需求或提升用户体验。

### 测试集管理

产生的原因测试同学在系统功能验证，以及搜索效果优化的过程中需要标注加工大量的数据，部分数据一直走的excel表格，录入库中也有很多格式问题。测试组长还期望能自定义展示的字段【标注字段很多】进行测试结果筛选，支持自定义的数据检索与或非逻辑的组合。

字段设置子模块：系统字段【强制展示】，非系统字段自由筛选添加，以用户维度建立了字段模板

【1】数据导入MultipartFile读文件夹，阿里的CustomExcelListener定制化解析excel表格的格式表头，数据大小等等

【2】递归筛选，与或非逻辑

**【3】与加工平台的结合**

```java
private List<Condition> recursionCondition(Condition condition, Map<Integer, Criteria> map, int level) {
    if (condition instanceof CompositeCondition) {
        CompositeCondition c = (CompositeCondition) condition;

        List<Condition> list = new ArrayList<>();
        for (Condition child : c.getChildren()) {
            list.addAll(recursionCondition(child, map, level + 1));
        }

        List<Criteria> criList = new ArrayList<>();
        list.forEach(i -> {
            LeafCondition item = (LeafCondition) i;
            Criteria criteria = fieldCriteria(item);
            if (null != criteria) {
                criList.add(criteria);
            }
        });

        Criteria criteria = new Criteria();
        if (!map.isEmpty() && map.containsKey(level + 1)) {
            criList.add(map.get(level + 1));
        }
        if (criList.size() == 1) {
            criteria = criList.get(0);
        } else {
            if (LogicOperatorEnum.AND.getCode().equals(c.getLogic())) {
                criteria.andOperator(criList);
            }
            if (LogicOperatorEnum.OR.getCode().equals(c.getLogic())) {
                criteria.orOperator(criList);
            }
        }

        map.put(level, criteria);

    } else if (condition instanceof LeafCondition) {
        return Collections.singletonList(condition);
    }
    return new ArrayList<>();
}
```

**逻辑**：

1. **处理复合条件（`CompositeCondition`）**：
   - 如果当前条件是复合条件（`CompositeCondition`），则递归处理其子条件。
   - 将子条件转换为 `Criteria` 并存储在 `criList` 中。
   - 根据复合条件的逻辑关系（AND/OR），使用 `andOperator` 或 `orOperator` 组合子条件。
   - 将组合后的 `Criteria` 存储在 `map` 中，键为当前层级（`level`）。
2. **处理叶子条件（`LeafCondition`）**：
   - 如果当前条件是叶子条件（`LeafCondition`），则直接返回该条件。
   - 叶子条件通常表示具体的字段查询条件（如 `field = value`）。
3. **返回结果**：
   - 对于复合条件，返回空列表（因为结果已经存储在 `map` 中）。
   - 对于叶子条件，返回包含该条件的单元素列表。

### 数据版本管理

需求产生：每周数据版本更新，同步3M数据，爬虫组临时发起数据更新发起我们配合总有数据无法对齐，服务互相影响的问题，mongo库的大小也受到了限制



上线下线的接口由服务端提供

数据同步的发起由爬虫组提供

运营中台用于核对bucket中的数据信息文件



3M数据信息文件

master表保存3m主表信息

 manager表保存各自3M库表的分区信息，

流程：

爬虫组发起上线冒烟测试---运营系统通知服务端冒烟测试数据同步--同步完成回传运营系统调用Minio Bucket存的Master表核对数据量是否一致---一致冒烟测试通过通知服务端全量上线--报错邮件告知服务端，日志记录终止上线回滚



### **什么是Minio？**

MinIO 是一个高性能、分布式、云原生的**对象存储系统**。它兼容 Amazon S3 API，可以用于存储和管理非结构化数据（如图片、视频、日志文件等）。MinIO 的设计目标是提供简单易用、高性能且可扩展的存储解决方案，适用于现代云原生应用和大数据场景。

#### **MinIO 的核心概念**

1. **Bucket（存储桶）**：
   - 类似于文件夹，用于组织和管理对象（文件）。
   - 每个 Bucket 可以有独立的权限和策略。
2. **Object（对象）**：
   - 存储在 MinIO 中的基本单元，可以是任意类型的文件。
3. **S3 API**：
   - MinIO 完全兼容 Amazon S3 API，支持标准的 S3 操作（如上传、下载、删除等）。
4. **分布式模式**：
   - MinIO 支持分布式部署，数据可以分散存储在多个节点上，提供高可用性和数据冗余。



#### 为什么 MinIO 适合存储 Milvus 和 ManticoreSearch

1. **高吞吐和低延迟**：
   - **Milvus**：作为向量数据库，Milvus 需要高效存储和检索大量向量数据，MinIO 的高吞吐和低延迟特性能够满足其需求。
   - **ManticoreSearch**：作为全文搜索引擎，ManticoreSearch 需要快速访问大量文档数据，MinIO 的性能优势有助于提升搜索效率。
2. **可扩展性**：
   - **Milvus**：随着数据量增长，MinIO 的分布式架构可以轻松扩展存储容量。
   - **ManticoreSearch**：MinIO 的扩展性支持其处理不断增长的文档数据。
3. **高可用性**：
   - **Milvus**：MinIO 的高可用性确保向量数据在节点故障时仍可访问。
   - **ManticoreSearch**：MinIO 的数据冗余和故障恢复机制保障搜索服务的连续性。
4. **兼容性**：
   - **Milvus** 和 **ManticoreSearch** 都可以通过 S3 API 与 MinIO 集成，简化了存储管理。

#### MinIO实例

ListObjectsArgs，RemoveObjectArgs

```java
/**
 * @param cluster
 * @param bucketName
 * 获取minio下bucket文件夹下的列表
 */
@Override
public List<String> listFilesInBucket(String cluster, String bucketName) {
    if (StringUtils.isEmpty(cluster) || !minioClientMap.containsKey(cluster)) {
        throw new IllegalArgumentException("Cluster is empty or not found in the map: " + cluster);
    }
    try {
        List<String> fileNames = new ArrayList<>();
        String continuationToken = null;
        do {
            ListObjectsArgs args = ListObjectsArgs.builder()
                    .bucket(bucketName)
                    .continuationToken(continuationToken)
                    .build();
            Iterable<Result<io.minio.messages.Item>> results = minioClientMap.get(cluster).listObjects(args);
            for (Result<io.minio.messages.Item> result : results) {
                io.minio.messages.Item item = result.get();
                if (item.isDir()) {
                    continue; // 跳过目录
                }
                fileNames.add(item.objectName());
            }
            // 检查是否有更多的对象可以列出
            continuationToken = args.continuationToken();
        } while (continuationToken != null);
        return fileNames;
    } catch (Exception e) {
        log.error("获取minio文件下的文件列表出现异常: {}", e.getMessage(), e);
    }
    return null;
}
```

```java
 /**
     * @author yffeng4
     * @Date: 2024/2/27 10:57
     * @Description: 根据bucket名称删除其中对应的数据
     **/
    @Override
    public boolean deleteDataFromBucket(String cluster, String bucketName) {
        if (StringUtils.isEmpty(cluster) || !minioClientMap.containsKey(cluster)) {
            throw new IllegalArgumentException("Cluster is empty or not found in the map: " + cluster);
        }
        try {
            boolean isTruncated = true;
            String continuationToken = null;
            while (isTruncated) {
                ListObjectsArgs args = ListObjectsArgs.builder()
                        .bucket(bucketName)
                        .continuationToken(continuationToken)
                        .recursive(true)
                        .build();
                Iterable<Result<io.minio.messages.Item>> results = minioClientMap.get(cluster).listObjects(args);
                for (Result<io.minio.messages.Item> result : results) {
                    Item item = result.get();
                    String objectName = item.objectName();

                    RemoveObjectArgs removeObjectArgs = RemoveObjectArgs.builder()
                            .bucket(bucketName)
                            .object(objectName)
                            .build();
                    minioClientMap.get(cluster).removeObject(removeObjectArgs);
                }
                // 检查是否有更多的对象可以列出
                continuationToken = args.continuationToken();
                isTruncated = continuationToken != null;
            }
            RemoveBucketArgs removeBucketArgs = RemoveBucketArgs.builder()
                    .bucket(bucketName)
                    .build();
            minioClientMap.get(cluster).removeBucket(removeBucketArgs);
            return true;
        } catch (Exception e) {
            log.error("删除bucket下的数据时出现异常: {}", e.getMessage(), e);
            return false;
        }
    }
```

### 什么是粗排、精排、重排

#### 粗排（Coarse Ranking）

- 定义
  - 粗排是搜索系统排序流程的第一个阶段，它的主要任务是从海量的候选文档集合中快速筛选出一部分相对优质的文档，减少后续精排阶段需要处理的数据量，以提高系统的整体效率。
- 特点
  - **速度快**：由于需要处理大量的候选文档，粗排算法通常比较简单、计算量小，能够在短时间内完成筛选。
  - **精度相对较低**：不会使用过于复杂的特征和模型来进行排序，只是进行一个初步的筛选。
- 实现方式
  - 一般会使用一些简单的特征和算法，如基于词频 - 逆文档频率（TF - IDF）、文本相似度等进行快速打分和排序。例如，在一个电商搜索系统中，粗排可能会根据商品标题与搜索关键词的匹配程度、商品的销量等简单特征，快速从数百万个商品中筛选出几千个商品进入下一轮排序。

#### 精排（Fine Ranking）



- 定义
  - 精排是在粗排筛选出的候选文档集合基础上，进行更细致、精确的排序。它会综合考虑更多的特征和因素，以提供更符合用户需求的搜索结果排序。
- 特点
  - **精度高**：会使用复杂的特征工程和强大的机器学习模型，充分考虑各种可能影响用户对搜索结果满意度的因素。
  - **计算资源消耗大**：由于需要处理更多的特征和使用更复杂的模型，精排的计算量相对较大，处理速度相对较慢。
- 实现方式
  - 通常会使用深度学习模型，如深度神经网络（DNN）、梯度提升决策树（GBDT）等。在训练模型时，会使用大量的标注数据，考虑多种特征，如用户的历史行为数据（点击、购买、收藏等）、文档的质量特征（内容质量、权威性等）、上下文信息等。例如，在搜索引擎中，精排会结合用户的搜索历史、当前搜索的上下文、网页的质量得分等信息，对粗排筛选出的结果进行精确排序。

#### 重排（Re - ranking）

- 定义
  - 重排是在精排结果的基础上，根据一些特定的规则或实时信息对搜索结果进行再次排序，以进一步优化搜索结果的排序质量。
- 特点
  - **灵活性高**：可以根据不同的业务需求和实时情况进行动态调整，以满足多样化的排序需求。
  - **通常考虑局部信息**：更关注当前搜索结果集合内的文档之间的关系和特定的业务规则。
- 实现方式
  - 重排的实现方式多种多样，可以基于规则，也可以使用简单的模型。例如，根据业务需求，将某些热门商品或广告置顶；或者根据实时的用户反馈信息（如当前页面的点击率）对搜索结果进行实时调整。在新闻搜索系统中，可能会根据新闻的时效性，对精排结果进行重排，将最新的新闻排在前面。

## 知识库加工平台

### 数据集管理

运营、测试、百科、QA数据，支持多条件、多格式、多段的数据导出

### 标注工作台

标注任务:task表，一个表只可能有多个数据集--数据池

用户任务表：user_task表，每个用户可以从一个标注任务中领取一个或多个数据集进行标注领取后生成task_batch

数据集批次表：task_batch，每有若干个用户领取若干个任务都会在对应的标注任务下形成数据批次，用于监控数据集标注完成数量

任务词条表：task_item,对待标注的词条进行人工标注

用户任务步骤表：user_task_step,任务分标注、检查、质检多个步骤

### 自建知识库上线管理

--针对于特殊数据和人工标注的数据

【1】爱标客数据、星图数据、医疗数据、时政数据、百科数据、qa数据。Ai资源部爱标客数据、六种数据

【2】各自有格式，面向其业务，设计了6种自建知识库的入库方式，6个大接口

【3】统一解析成一个模板，有些kafka有些redis有些es，调用其它接口

【4】首先汇总到知识库加工平台mongo库中

【5】发起数据版本上线，冒烟测试，再全量写3M库构建文本索引和向量索引，中台--》爬虫平台&服务端

【6】自建知识库每次量级不大，上线速度快，一般告警先通过日志终止查找问题，再走线上环境

### 其他模块

如数据报表、标注团队管理、异常数据管理

## 用户中心服务

### **个人中心集中配置**

依托Springboot可灵活配置特性,设计Config类支持部分功能和属性的灵活配置

### **个人中心用户信息**

对教育bg所有用户个人信息根据不同业务条线结合角色、学区进行展示与编辑

### **手机号邮箱密码管理**

集合redis设计Token进行全流程安全校验，支持三种登录方式的绑定解绑换绑

需要多步验证的，给出串行redis的token防止跳步

### **三方账号管理**

集成微信微博QQ三方账号api，根据业务支持关联账号、孩子账号、三方账号的绑定解绑

经过调研，配置统一的请求发送工具类，调用对应的api，根据返回结果在库

### 日志记录组件

```java
import org.aspectj.lang.JoinPoint;
import org.aspectj.lang.annotation.AfterReturning;
import org.aspectj.lang.annotation.AfterThrowing;
import org.aspectj.lang.annotation.Aspect;
import org.aspectj.lang.reflect.MethodSignature;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;

import java.lang.reflect.Method;

@Aspect
@Component
public class LogAspect {
    @Autowired
    private KafkaLogProducer kafkaLogProducer;

    @AfterReturning(pointcut = "execution(* com.example.usercenter.controller.*.*(..))", returning = "result")
    public void logAfterReturning(JoinPoint joinPoint, Object result) {
        recordLog(joinPoint, true);
    }

    @AfterThrowing(pointcut = "execution(* com.example.usercenter.controller.*.*(..))", throwing = "ex")
    public void logAfterThrowing(JoinPoint joinPoint, Throwable ex) {
        recordLog(joinPoint, false);
    }

    private void recordLog(JoinPoint joinPoint, boolean success) {
        MethodSignature signature = (MethodSignature) joinPoint.getSignature();
        Method method = signature.getMethod();
        String interfaceName = method.getName();
        String userId = getUserIdFromArgs(joinPoint.getArgs());

        LogEntity log = new LogEntity();
        log.setUserId(userId);
        log.setAction(interfaceName);
        log.setInterfaceName(interfaceName);
        log.setSuccess(success);

        kafkaLogProducer.sendLog(log);
    }

    private String getUserIdFromArgs(Object[] args) {
        // 这里简单假设第一个参数是用户 ID，实际中根据情况修改
        return args.length > 0 ? args[0].toString() : "unknown";
    }
}
```

日志服务搜索器

```java
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.data.elasticsearch.core.ElasticsearchOperations;
import org.springframework.data.elasticsearch.core.SearchHit;
import org.springframework.data.elasticsearch.core.SearchHits;
import org.springframework.data.elasticsearch.core.query.Criteria;
import org.springframework.data.elasticsearch.core.query.CriteriaQuery;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.bind.annotation.RestController;

import java.util.ArrayList;
import java.util.List;

@RestController
public class LogSearchController {
    @Autowired
    private ElasticsearchOperations elasticsearchOperations;

    @GetMapping("/logs/search")
    public List<LogEntity> searchLogs(@RequestParam(required = false) String userId,
                                      @RequestParam(required = false) String interfaceName,
                                      @RequestParam(required = false) Boolean success) {
        Criteria criteria = new Criteria();
        if (userId != null) {
            criteria.and("userId").is(userId);
        }
        if (interfaceName != null) {
            criteria.and("interfaceName").is(interfaceName);
        }
        if (success != null) {
            criteria.and("success").is(success);
        }

        CriteriaQuery query = new CriteriaQuery(criteria);
        SearchHits<LogEntity> searchHits = elasticsearchOperations.search(query, LogEntity.class);
        List<LogEntity> logs = new ArrayList<>();
        for (SearchHit<LogEntity> hit : searchHits) {
            logs.add(hit.getContent());
        }
        return logs;
    }
}
```

## **UC-权限管理系统**

用户赋予角色，角色绑定菜单，菜单赋予功能

妥协的方式

●**接口鉴权：**结合Spring security,filterInvocation中获取请求，Authentation中解析用户角色，根据数据库的灵活配置将访问请求与允许该角色访问的路径进行匹配鉴权，保护系统的安全与机密性。

## 回流日志服务改造

# 携项目管理

# Docker

**Docker** 是一个开源的容器化平台，用于开发、部署和运行应用程序。它通过将应用程序及其依赖项打包到一个轻量级的容器中，使应用程序可以在任何环境中一致运行。Docker 容器与虚拟机不同，容器共享主机操作系统的内核，因此更加轻量、启动更快、资源占用更少。

## Docker 的核心概念：

1. **镜像（Image）**：一个只读模板，包含运行应用程序所需的代码、库、环境变量和配置文件。
2. **容器（Container）**：镜像的运行实例，是一个独立的、可执行的进程。
3. **Dockerfile**：一个文本文件，包含构建镜像的指令。
4. **仓库（Registry）**：用于存储和分发 Docker 镜像的服务，如 Docker Hub。



## 上传docker镜像

### **创建 Docker 镜像**

**方法 1：通过 Dockerfile 构建镜像**

Dockerfile 是一个文本文件，包含构建镜像的指令。以下是创建镜像的步骤：

1. **编写 Dockerfile**
   在项目根目录下创建一个名为 `Dockerfile` 的文件，内容示例如下：

   Dockerfile

   复制

   ```
   # 使用基础镜像
   FROM ubuntu:20.04
   
   # 设置工作目录
   WORKDIR /app
   
   # 复制文件到容器中
   COPY . .
   
   # 安装依赖
   RUN apt-get update && apt-get install -y python3
   
   # 暴露端口
   EXPOSE 80
   
   # 设置启动命令
   CMD ["python3", "app.py"]
   ```

2. **构建镜像**
   在 Dockerfile 所在目录下运行以下命令：

   bash

   复制

   ```
   docker build -t <镜像名>:<标签> .
   ```

   例如：

   bash

   复制

   ```
   docker build -t myapp:1.0 .
   ```

   - `-t`：指定镜像的名称和标签。
   - `.`：表示 Dockerfile 所在的当前目录。

3. **查看本地镜像**
   构建完成后，可以通过以下命令查看本地镜像：

   bash

   复制

   ```
   docker images
   ```

**方法 2：通过容器创建镜像**

如果你已经有一个正在运行的容器，可以基于该容器创建镜像：

1. **运行容器**：

   bash

   复制

   ```
   docker run -it ubuntu:20.04 /bin/bash
   ```

2. **在容器中修改内容**：
   例如，安装一些软件：

   bash

   复制

   ```
   apt-get update && apt-get install -y curl
   ```

3. **提交容器为镜像**：
   退出容器后，运行以下命令：

   bash

   复制

   ```
   docker commit <容器ID> <镜像名>:<标签>
   ```

   例如：

   bash

   复制

   ```
   docker commit abc123 myapp:1.0
   ```

------

### **上传 Docker 镜像到仓库**

Docker 镜像可以上传到 Docker Hub 或其他私有仓库（如 AWS ECR、阿里云容器镜像服务等）。以下是上传到 Docker Hub 的步骤：

**步骤 1：登录 Docker Hub**

1. 如果没有 Docker Hub 账号，先注册一个：[Docker Hub](https://hub.docker.com/)。

2. 使用以下命令登录：

   bash

   复制

   ```
   docker login
   ```

   输入用户名和密码。

**步骤 2：为镜像打标签**

在上传之前，需要为本地镜像打上符合 Docker Hub 命名规范的标签：

bash

复制

```
docker tag <本地镜像名>:<标签> <Docker Hub用户名>/<镜像名>:<标签>
```

例如：

bash

复制

```
docker tag myapp:1.0 mydockerhubusername/myapp:1.0
```

**步骤 3：上传镜像**

使用以下命令上传镜像：

bash

复制

```
docker push <Docker Hub用户名>/<镜像名>:<标签>
```

例如：

bash

复制

```
docker push mydockerhubusername/myapp:1.0
```

**步骤 4：验证上传**

登录 Docker Hub，在仓库中查看是否成功上传。

bash

复制

```
docker push <私有仓库URI>/<镜像名>:<标签>
```

------

### 示例：完整流程

1. **编写 Dockerfile**：

   Dockerfile

   复制

   ```
   FROM nginx:latest
   COPY index.html /usr/share/nginx/html
   EXPOSE 80
   ```

2. **构建镜像**：

   bash

   复制

   ```
   docker build -t mynginx:1.0 .
   ```

3. **打标签**：

   bash

   复制

   ```
   docker tag mynginx:1.0 mydockerhubusername/mynginx:1.0
   ```

4. **上传镜像**：

   bash

   docker push <私有仓库URI>/<镜像名>:<标签>

# k8s

## 命令

`kubectl` 是 Kubernetes 的命令行工具，用于与 Kubernetes 集群进行交互。通过 `kubectl`，用户可以管理集群中的资源，如部署应用、查看日志、调试服务等。

### 集群管理

1. **查看集群信息**：

   bash

   复制

   ```
   kubectl cluster-info
   ```

2. **查看节点状态**：

   bash

   复制

   ```
   kubectl get nodes
   ```

### 资源管理

1. **查看所有资源**：

   bash

   复制

   ```
   kubectl get all
   ```

2. **查看 Pod**：

   bash

   复制

   ```
   kubectl get pods
   ```

3. **查看 Service**：

   bash

   复制

   ```
   kubectl get services
   ```

4. **查看 Deployment**：

   bash

   复制

   ```
   kubectl get deployments
   ```

5. **查看命名空间**：

   bash

   复制

   ```
   kubectl get namespaces
   ```

# 多线程

# kafka



# ES

## 倒排索引的结构与原理分词（Term）
这种情况下，如果要想快速地检索到目标文章，则必须将文章分割成一个个关键字，再将关键词与文章建立索引关系。Elasticsearch里分词关键字称作term。

例：i am happy用elasticsearch标准分词器切分的关键字结果是i,am,happy

倒排列表（posting list）
根据切分好的关键字，将关键字与包含该关键字的文档进行关联，组成的结构称为倒排列表，即倒排索引。

如文档doc1包含内容i am happy，文档doc2包含内容i am your father，拆解成的倒排列表如下：


倒排索引主要由两个部分组成：

- **词典（Dictionary）**：存储文档中所有唯一的词（term）。
- **倒排列表（Posting List）**：每个词对应一个列表，包含所有包含该词的文档 ID，以及其他相关信息，如词频（TF）和文档频率（DF）。

![image-20250312215242681](C:\Users\Brantu\AppData\Roaming\Typora\typora-user-images\image-20250312215242681.png)

## 倒排索引的工作流程

文档分析：将文档中的文本分解为词项（tokens），并进行标准化处理（如小写化、去除停用词）。
构建索引：为每个词项在词典中创建条目，并将对应的文档 ID 添加到倒排列表中。
搜索请求：当接收到搜索请求时，Elasticsearch 将查询的词项映射到倒排索引，快速找到相关文档。

## 基本类型

 **字符串类型（Text 和 Keyword）**
Text：

用于分析的文本字段，适合全文搜索。
存储时会被分词（tokenization），便于查找。
适用于长文本，如文章、描述等。
示例：

```java
"description": {
  "type": "text"
}
```

**Keyword：**

不进行分析的字符串字段，适合精确匹配。
通常用于 ID、标签、类别等需要精确查询的字段。
示例：

```
"category": {
  "type": "keyword"
}
```


 **数字类型（Integer, Float, Double, etc.）**
**Integer：**

整数类型，适用于整数字段。
示例：

```
"age": {
  "type": "integer"
}
```

**Float、Double：**

浮点数类型，适合存储小数。
示例：

```
"price": {
  "type": "float"
}
```


**布尔类型（Boolean）**
Boolean：

只存储 true 或 false 值。
示例：

```
"is_active": {
  "type": "boolean"
}
```

**期类型**
Date：

用于存储日期和时间，支持多种日期格式。
示例：

```
"created_at": {
  "type": "date",
  "format": "yyyy-MM-dd'T'HH:mm:ss.SSSZ"
}
```

**对象和嵌套类型**
**对象类型（Object）**
Object：

用于存储 JSON 对象，字段可以嵌套。
适合存储复杂的数据结构。
示例：

```java
"address": {
  "type": "object",
  "properties": {
    "city": { "type": "keyword" },
    "zip": { "type": "integer" }
  }
}
```

**嵌套类型（Nested）**
Nested：

专门用于处理数组中的对象，确保在查询时保持对象之间的关系。
避免在传统对象类型中因扁平化导致的数据混乱。
示例：

```
"comments": {
  "type": "nested",
  "properties": {
    "user": { "type": "keyword" },
    "message": { "type": "text" }
  }
}
```


以下是一个完整的映射示例，展示了多种字段类型的结合使用：

```java
PUT /my_index
{
  "mappings": {
    "properties": {
      "title": {
        "type": "text"
      },
      "author": {
        "type": "keyword"
      },
      "published_date": {
        "type": "date"
      },
      "price": {
        "type": "float"
      },
      "tags": {
        "type": "keyword"
      },
      "comments": {
        "type": "nested",
        "properties": {
          "user": { "type": "keyword" },
          "message": { "type": "text" }
        }
      },
      "location": {
        "type": "geo_point"
      }
    }
  }
}
```

## ES的理解

【1】**index索引，在es中代表着数据库**

**库里有一定的mapping映射，它是对索引库中文档的约束，创建索引时同步构建mapping映射**

常见的mapping

type：字段数据类型，常见的简单类型有：
字符串：text（可分词的文本）、keyword（精确值，例如：品牌、国家、ip地址）
数值：long、integer、short、byte、double、float、
布尔：boolean
日期：date
对象：object
index：是否创建索引，默认为true
analyzer：使用哪种分词器，ik_max_word和ik_smart模式。**ik_max_word:** 会将文本做最细粒度的拆分； **ik_smart**会做最粗粒度的拆分

properties：该字段的子段

【2】对于修改索引，因此索引库**一旦创建，无法修改mapping，因为会触发倒排索引重构**。虽然无法修改mapping中已有的字段，但是却允许添加新的字段到mapping中，因为不会对倒排索引产生影响。

【3】es的存储方式是倒排索引，在插入文档的时候就会形成，内部保存的是分词在文档中的位置（？）

【4】restful格调用，**在hit中会看到命中的文档结果**



term与dictionary

## java实例与es中的映射

```java
public class Employee {
 
  private String email;
  private String firstName;
  private String lastName;
  private EmployeeInfo info;
  private Date joinDate;
 
}
```

```java
private class EmployeeInfo {
 
  private String bio; // 性格
  private Integer age;
  private String[] interests; // 兴趣爱好
 
}
```

```json
{
    "email":  "zhupei@tianfang1314.cn",
    "first_name": "pei",
    "last_name": "zhu",
    "info": {
    "bio": "curious and modest",
    "age": 25,
    "interests": [ "bike", "run" ]
    },
    "join_date": "2017/11/07"
}
```

## ES的语法

查询集群有哪些索引

```java
GET /_cat/indices?v
```

### 索引库

**创建索引库**

```java
PUT /索引库名称
{
  "mappings": {
    "properties": {
      "字段名":{
        "type": "text",
        "analyzer": "ik_smart"
      },
      "字段名2":{
        "type": "keyword",
        "index": "false"
      },
      "字段名3":{
        "properties": {
          "子字段": {
            "type": "keyword"
          }
        }
      },
      // ...略
    }
  }
}

```

eg:

```java
PUT /my_index
{
  "mappings": {
    "properties": {
      "title": {
        "type": "text"
      },
      "author": {
        "type": "keyword"
      },
      "published_date": {
        "type": "date"
      },
      "price": {
        "type": "float"
      },
      "tags": {
        "type": "keyword"
      },
      "comments": {
        "type": "nested",
        "properties": {
          "user": { "type": "keyword" },
          "message": { "type": "text" }
        }
      },
      "location": {
        "type": "geo_point"
      }
    }
  }
}

```

**获取索引库**

```
GET /索引库名
```

![image-20250313172329849](C:\Users\Brantu\AppData\Roaming\Typora\typora-user-images\image-20250313172329849.png)

**删除索引库**

```java
DELETE /索引库名
```

**修改索引库**

```java
PUT /索引库名/_mapping
{
  "properties": {
    "新字段名":{
      "type": "integer"
    }
  }
}

```

### 针对文档使用

#### **新增文档**

```json
POST /索引库名/_doc(type)/文档id
{
    "字段1": "值1",
    "字段2": "值2",
    "字段3": {
        "子属性1": "值3",
        "子属性2": "值4"
    },
    // ...
}

PUT /shoes/product/1
{
    "name" : "NB 鞋子",
    "desc" :  "特别好的鞋子",
    "price" :  530,
    "producer" :  "NB producer",
    "tags": [ "实用", "美观" ]
}

```

![image-20250313173310307](C:\Users\Brantu\AppData\Roaming\Typora\typora-user-images\image-20250313173310307.png)

#### **查询文档**

**普通查询**

```
GET /customer/_doc/1
```

**批量查询**

`match_all`表示查询所有的数据，sort即按照什么字段排序

```json
GET /bank/_search
{
  "query": { "match_all": {} },
  "sort": [
    { "account_number": "asc" }
  ]
}
```

**分页查询**

本质上就是from和size两个字段

```json
GET /bank/_search
{
  "query": { "match_all": {} },
  "sort": [
    { "account_number": "asc" }
  ],
  "from": 10,
  "size": 10
}
```

**指定字段查询：match**

如果要在字段中搜索特定字词，可以使用`match`; 如下语句将查询address 字段中包含 mill 或者 lane的数据

```json
GET /bank/_search
{
  "query": { "match": { "address": "mill lane" } }
}
```

![image-20250313175718282](C:\Users\Brantu\AppData\Roaming\Typora\typora-user-images\image-20250313175718282.png)

**查询段落匹配：match_phrase**

如果我们希望查询的条件是 address字段中包含 “mill lane”，则可以使用`match_phrase`

```json
GET /bank/_search
{
  "query": { "match_phrase": { "address": "mill lane" } }
}
```

**多条件查询: bool**

must：文档必须匹配的条件，类似于 SQL 的 AND。例如：
field1 必须包含 value1。
field2 必须在 [10, 20] 范围内。

should：非必须条件，匹配的条件越多，相关性得分（*score）越高。至少有一个条件匹配时，文档会更相关。
field3 或 field4 中匹配一个即可加分。

must_not：文档不能包含的条件，类似于 SQL 的 NOT。
排除 field5 等于 excluded_value 的文档。

filter：过滤条件，类似于 must，但不影响相关性评分（score），性能较高。
field6 必须为 filtered_value。

```json
GET your_index/_search
{
  "query": {
    "bool": {
      "must": [
        {
          "match": {
            "field1": "value1"
          }
        },
        {
          "range": {
            "field2": {
              "gte": 10,
              "lte": 20
            }
          }
        }
      ],
      "should": [
        {
          "term": {
            "field3": "optional_value1"
          }
        },
        {
          "term": {
            "field4": "optional_value2"
          }
        }
      ],
      "must_not": [
        {
          "term": {
            "field5": "excluded_value"
          }
        }
      ],
      "filter": [
        {
          "term": {
            "field6": "filtered_value"
          }
        }
      ]
    }
  }
}
```





## 集成入java中的使用

## 实战案例

# 设计模式

## **单例模式（Singleton Pattern）**

**目的**：确保一个类只有一个实例，并提供全局访问点。

单例模式是一种创建型设计模式，**它确保一个类只有一个实例，并提供一个全局访问点来获取这个实例**。在某些场景下，如数**据库连接池、线程池、配置文件管理等，需要确保系统中某个类只有一个实例存在**，避免资源的浪费和不一致性问题。

**实现方式**·

- **饿汉式**



```java
public class EagerSingleton {
    // 在类加载时就创建实例
    private static final EagerSingleton INSTANCE = new EagerSingleton();

    // 私有构造函数，防止外部实例化
    private EagerSingleton() {}

    // 提供公共的静态方法获取实例
    public static EagerSingleton getInstance() {
        return INSTANCE;
    }
}
```



- **懒汉式（线程不安全）**



```java
public class LazySingleton {
    private static LazySingleton instance;

    private LazySingleton() {}

    public static LazySingleton getInstance() {
        if (instance == null) {
            instance = new LazySingleton();
        }
        return instance;
    }
}
```



- **懒汉式（线程安全，使用 synchronized）**



```java
public class ThreadSafeLazySingleton {
    private static ThreadSafeLazySingleton instance;

    private ThreadSafeLazySingleton() {}

    public static synchronized ThreadSafeLazySingleton getInstance() {
        if (instance == null) {
            instance = new ThreadSafeLazySingleton();
        }
        return instance;
    }
}
```



- **双重检查锁定（DCL）**

```java
public class DoubleCheckedLockingSingleton {
    private static volatile DoubleCheckedLockingSingleton instance;

    private DoubleCheckedLockingSingleton() {}

    public static DoubleCheckedLockingSingleton getInstance() {
        if (instance == null) {
            synchronized (DoubleCheckedLockingSingleton.class) {
                if (instance == null) {
                    instance = new DoubleCheckedLockingSingleton();
                }
            }
        }
        return instance;
    }
}
```



- **静态内部类**

```java
public class StaticInnerClassSingleton {
    private StaticInnerClassSingleton() {}

    private static class SingletonHolder {
        private static final StaticInnerClassSingleton INSTANCE = new StaticInnerClassSingleton();
    }

    public static StaticInnerClassSingleton getInstance() {
        return SingletonHolder.INSTANCE;
    }
}
```

**应用场景**：

- 数据库连接池。
- 配置文件管理器。

## **工厂模式（Factory Pattern）**

**目的**：定义一个创建对象的接口，但由子类决定实例化哪个类。

工厂模式是一种创建型设计模式，它**提供了一种创建对象的方式，将对象的创建和使用分离**。通过使用工厂模式，可以将对象的创建逻辑封装在一个工厂类中，使得代码更具可维护性和可扩展性。

实现方式

- **简单工厂模式**

```java
// 产品接口
interface Shape {
    void draw();
}

// 具体产品类
class Circle implements Shape {
    @Override
    public void draw() {
        System.out.println("Drawing a circle");
    }
}

class Rectangle implements Shape {
    @Override
    public void draw() {
        System.out.println("Drawing a rectangle");
    }
}

// 简单工厂类
class ShapeFactory {
    public static Shape getShape(String shapeType) {
        if ("circle".equalsIgnoreCase(shapeType)) {
            return new Circle();
        } else if ("rectangle".equalsIgnoreCase(shapeType)) {
            return new Rectangle();
        }
        return null;
    }
}
```



- **工厂方法模式**

```java
// 产品接口
interface Product {
    void use();
}

// 具体产品类
class ConcreteProductA implements Product {
    @Override
    public void use() {
        System.out.println("Using product A");
    }
}

class ConcreteProductB implements Product {
    @Override
    public void use() {
        System.out.println("Using product B");
    }
}

// 工厂接口
interface Factory {
    Product createProduct();
}

// 具体工厂类
class ConcreteFactoryA implements Factory {
    @Override
    public Product createProduct() {
        return new ConcreteProductA();
    }
}

class ConcreteFactoryB implements Factory {
    @Override
    public Product createProduct() {
        return new ConcreteProductB();
    }
}
```



**应用场景**：

- 日志记录器。
- 数据库驱动加载。

## **抽象工厂模式（Abstract Factory Pattern）**

**目的**：提供一个创建一系列相关或相互依赖对象的接口，而无需指定具体类。

**经典案例**：

java

复制

```
interface GUIFactory {
    Button createButton();
    Checkbox createCheckbox();
}

class WinFactory implements GUIFactory {
    @Override
    public Button createButton() {
        return new WinButton();
    }
    @Override
    public Checkbox createCheckbox() {
        return new WinCheckbox();
    }
}

class MacFactory implements GUIFactory {
    @Override
    public Button createButton() {
        return new MacButton();
    }
    @Override
    public Checkbox createCheckbox() {
        return new MacCheckbox();
    }
}
```

**应用场景**：

- 跨平台 UI 组件库。
- 数据库连接工厂。

## **适配器模式（Adapter Pattern）**

**定义**：适配器模式是一种结构型设计模式，它允许将一个类的接口转换成客户希望的另一个接口。适配器模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。

**实现方式**  ·



- **类适配器模式**

```java
// 目标接口
interface Target {
    void request();
}

// 适配者类
class Adaptee {
    public void specificRequest() {
        System.out.println("Specific request");
    }
}

// 适配器类
class ClassAdapter extends Adaptee implements Target {
    @Override
    public void request() {
        specificRequest();
    }
}
```



- **对象适配器模式**

```java
// 目标接口
interface Target {
    void request();
}

// 适配者类
class Adaptee {
    public void specificRequest() {
        System.out.println("Specific request");
    }
}

// 适配器类
class ObjectAdapter implements Target {
    private Adaptee adaptee;

    public ObjectAdapter(Adaptee adaptee) {
        this.adaptee = adaptee;
    }

    @Override
    public void request() {
        adaptee.specificRequest();
    }
}
```

**应用场景**：

- 集成第三方库。
- 兼容旧系统。

## 观察者模式

**定义**：观察者模式是一种行为型设计模式，它定义了一种一对多的依赖关系，让多个观察者对象同时监听一个主题对象。这个主题对象在状态发生变化时，会通知所有观察者对象，使它们能够自动更新自己的状态。

**实现方式**

```java
import java.util.ArrayList;
import java.util.List;

// 主题接口
interface Subject {
    void registerObserver(Observer observer);
    void removeObserver(Observer observer);
    void notifyObservers();
}

// 具体主题类
class ConcreteSubject implements Subject {
    private List<Observer> observers = new ArrayList<>();
    private int state;

    public int getState() {
        return state;
    }

    public void setState(int state) {
        this.state = state;
        notifyObservers();
    }

    @Override
    public void registerObserver(Observer observer) {
        observers.add(observer);
    }

    @Override
    public void removeObserver(Observer observer) {
        observers.remove(observer);
    }

    @Override
    public void notifyObservers() {
        for (Observer observer : observers) {
            observer.update(state);
        }
    }
}

// 观察者接口
interface Observer {
    void update(int state);
}

// 具体观察者类
class ConcreteObserver implements Observer {
    private int observerState;

    @Override
    public void update(int state) {
        observerState = state;
        System.out.println("Observer state updated to: " + observerState);
    }
}
```

# Xshell命令操作【日志查看，部署】

## ps -ef | grep nginx

获取所有ng信息，命令用于报告当前系统的进程状态。

## 查看linux内存情况

### `free` 命令

`free` 命令用于显示系统内存的使用情况，包括物理内存、交换内存（swap）的使用情况。

```bash
free -h
```

- -h` 选项：以人类可读的格式显示内存大小，例如使用 GB、MB 等单位。

### `vmstat` 命令

`vmstat` 可以报告关于内核线程、虚拟内存、磁盘、陷阱和 CPU 活动的统计信息。

```bash
vmstat 1 5
```

- 第一个参数 `1` 表示每隔 1 秒刷新一次统计信息。
- 第二个参数 `5` 表示总共刷新 5 次。

### `top` 命令

`top` 是一个动态实时监控进程活动的工具，它可以显示系统中各个进程的资源占用情况，包括 CPU、内存等

进入 `top` 界面后，你可以看到以下重要信息：

- **系统信息**：显示系统的整体状态，如当前时间、系统运行时间、登录用户数、系统负载等。
- **进程信息**：列出当前系统中占用资源较多的进程，包括进程 ID（PID）、用户（USER）、CPU 使用率（% CPU）、内存使用率（% MEM）等。

在 `top` 界面中，你还可以使用一些快捷键进行操作：

- q`：退出 `top` 界面。
- `M`：按照内存使用率排序。
- `P`：按照 CPU 使用率排序。

## cd相关

工程基本部署在/data/server下

日志记录在log目录进对应的工程下：

cd  /data/log/项目名称/

cd .. 

cd ./data

1. **cd**：不带参数时，返回用户的主目录。例如：

   ```
   bashcd
   ```

   这会将当前目录更改为用户的主目录。

2. **cd 目录路径**：将当前工作目录更改为指定的目录路径。例如：

   ```
   bashcd /home/user/documents
   ```

   这会将当前目录更改为 `/home/user/documents`。

3. **cd ~** 或 **cd**：这两种方式都可以返回用户的主目录。例如：

   ```
   bashcd ~
   ```

   或者简单地：

   ```
   bashcd
   ```

4. **cd -**：切换到上次所在的目录。例如，如果你先切换到 `/home/user/documents`，然后切换到其他目录，再执行 `cd -`，就会回到 `/home/user/documents`。

5. **cd ..**：返回上一级目录。例如：

   ```
   bashcd ..
   ```

   这会将当前目录更改为上级目录。

6. **cd ../..**：返回上两级目录，依此类推，可以使用多个 `..` 来向上跳转多级目录。

7. **cd /**：返回到根目录。例如：

   ```
   bashcd /
   ```

8. **cd ~username**：切换到指定用户的主目录。例如：

   ```
   bashcd ~john
   ```

   这会将当前目录更改为用户 `john` 的主目录。

这些是 `cd` 命令的一些常见用法和相关命令。`cd` 是命令行中常用的基本命令，用来在不同目录之间切换和操作文件系统。

## tail -f  xxx.log 实时查看

### 解释：

1. **`tail` 命令**：`tail` 是一个常用的命令行工具，用于显示文件末尾的内容。
2. **`-f` 参数**：`-f` 参数代表 `follow`，即跟随文件内容的变化。在实时监控文件时，`tail -f` 会持续显示文件的最新内容，并且不会退出命令，而是继续等待新的数据。
3. **`-`n 参数**：参数告诉 `tail` 命令显示文件的最后100行。
4. **`xxx.log`**：这是文件名，通常是你希望监控的日志文件名或其他文本文件名。

### 使用场景：

- **日志监控**：最常见的用途是实时监控日志文件的变化。例如，你可以在终端运行 `tail -f error.log` 来实时查看 `error.log` 文件中新添加的错误信息。
- **调试和分析**：开发人员和系统管理员可以使用 `tail -f` 命令来实时查看和分析正在发生的事情，如程序输出或系统日志。
- **持续更新的输出**：在需要持续获取某个文件尾部变化的情况下，`tail -f` 提供了一种简单有效的方式来达到这个目的，而不需要反复手动执行命令。

总之，`tail -f xxx.log` 命令可以帮助你实时查看文件内容的变化，特别适合于需要跟踪日志文件的情况。

## grep 'xxx' stdout.log

抓取带xxx内容的log日志

## curl发送请求的

`curl` 

是一个命令行工具和库，用于传输数据，支持多种协议，包括 HTTP、HTTPS、FTP 等。它在 Unix、Linux 和类 Unix 系统上广泛使用，并且有 Windows 版本。

1. **下载文件：** 使用 `curl` 可以通过 HTTP、HTTPS、FTP 等协议下载文件。例如：

   ```
   bashcurl -O https://example.com/file.zip
   ```

   这将从指定 URL 下载文件并保存在当前目录。

2. **发送请求：** `curl` 可以用来发送 HTTP 请求并获取响应。这对于测试 Web 服务的响应或自动化脚本中的数据传输非常有用。例如：

   ```
   bashcurl -X GET https://api.example.com/data
   ```

   或者：

   ```
   bashcurl -X POST -d '{"key": "value"}' -H "Content-Type: application/json" https://api.example.com/endpoint
   ```

   这些命令分别发送 GET 和 POST 请求，获取或发送数据到指定的 API 端点。

3. **处理 REST API：** 开发者经常使用 `curl` 来与 RESTful API 进行交互。它可以模拟各种 HTTP 请求方法（GET、POST、PUT、DELETE 等），并支持自定义头部信息和请求体数据。

4. **上传文件：** 除了下载，`curl` 也支持上传文件到远程服务器，使用 `-T` 参数。例如：

   ```
   bashcurl -T uploadfile.txt ftp://ftp.example.com/upload/
   ```

   这将上传本地的 `uploadfile.txt` 文件到 FTP 服务器上的指定目录。

5. **测试和调试：** `curl` 在开发和调试过程中是一个强大的工具，可以快速验证 Web 服务是否正常工作，或者用来获取远程服务器的响应头和内容，检查 HTTP 状态码等。

6. **支持代理：** `curl` 支持使用代理服务器发送和接收数据，这对于访问需要通过代理的网络非常有用。

7. **文件传输支持：** `curl` 支持断点续传、文件断点续传等高级功能，可以更安全地下载和上传大文件。

总之，`curl` 是一个功能强大的命令行工具，适用于多种网络传输需求，是系统管理员、开发人员和测试人员经常使用的工具之一。

## cat stdout.2024-07*.log | grep '学生' --color

- `cat` 命令用于连接文件并打印到标准输出。
- `stdout.2024-07*.log` 使用了通配符 `*`，表示所有以 `stdout.2024-07` 开头且以 `.log` 结尾的文件名。这里假设 `2024-07*` 是匹配到的文件名部分，可能包括多个文件，如 `stdout.2024-07-01.log`, `stdout.2024-07-15.log` 等。
- `cat stdout.2024-07*.log` 将会把所有符合条件的日志文件内容输出到标准输出。
- **`grep '学生' --color`**：
  - `grep` 是一个强大的文本搜索工具，用于在文件或标准输入中查找匹配某个模式的行。
  - `'学生'` 是要搜索的模式，即需要在日志文件中查找包含 `学生` 关键词的行。
  - `--color` 参数会使匹配的文本以颜色高亮显示，这可以提高可读性，但在某些环境中可能需要适当配置才能生效

`grep` 命令有很多选项可以用来进行更复杂的搜索，如 `-i` 忽略大小写，`-v` 反向查找不匹配的行，`-E` 支持正则表达式等

## vim编辑命令

### 使用快捷键进行退出

1、按“Esc”键进入命令模式

当我们在vim编辑模式下输入完毕需要进行退出操作时，首先需要按下“Esc”键，将vim编辑器从插入模式或者替换模式切换到命令模式。

    ESC

2、输入“:wq”保存并退出

在命令模式下，输入“:wq”命令，表示保存并退出vim编辑器。

    :wq

3、输入“:q!”强制退出

当我们在未保存文件的情况下，需要强制退出vim编辑器时，可以在命令模式下输入“:q!”命令。

    :q!

### 使用菜单进行退出

1、按“Esc”键进入命令模式

同样需要进入命令模式，按下“Esc”键。

    ESC

2、输入“:w”保存

在命令模式下，输入“:w”命令，表示保存文件。

    :w

3、按下“Shift + Z + Z”退出

在命令模式下，按下“Shift + Z + Z”快捷键，表示保存并退出vim编辑器。

    Shift + Z + Z

### 使用vim的扩展命令进行退出

1、按“Esc”键进入命令模式

同样需要进入命令模式，按下“Esc”键。

    ESC

2、输入“:x”保存并退出

在命令模式下，输入“:x”命令，表示保存并退出vim编辑器。

    :x

3、输入“:wqa”保存全部并退出

在命令模式下，输入“:wqa”命令，表示保存全部并退出vim编辑器。

    :wqa

## 部署流程：

涉及的命令：

lsof -i：端口号 查看某个端口号所在的进程号

pwds 进程号 ： 获取该进程所在的文件路径

kill -9: 强制结束某个进程

rm 文件名：删除某个文件

rm -rf： 删除文件夹全部内容，且不经过删除确认

mkdir folder_name 

rz -be：进到某个目录下，将打好的tar包上传到指定位置

解压包相关：

tar -xvf    解压.tar

tar -xvzf  解压.tar.gz 或 .tgz 文件

启动用启动脚本，sh start.sh启动项目

杀死进程，删掉tar包，上传新的，解压运行







# 携程工作记录





















# 面试Java基础补缺

## G1收集器和CMS收集器的区别，为什么G1被提出和取代

### G1 收集器和 CMS 收集器的区别

 **设计目标**



- **CMS（Concurrent Mark Sweep）收集器**：其主要目标是获取最短回收停顿时间，在进行垃圾回收时，尽量减少应用程序的停顿时间，以达到较好的响应性能，适合对响应时间要求较高的应用，如 Web 应用。
- **G1（Garbage - First）收集器**：面向服务端应用，目标是在满足高吞吐量的同时，尽可能地控制垃圾回收的停顿时间。它可以在大内存、多处理器的环境下表现良好，既能保证应用程序的性能，又能有效地管理内存。

**内存布局**



- **CMS 收集器**：采用传统的分代收集思想，将堆内存划分为新生代（又分为 Eden 区和两个 Survivor 区）和老年代，不同代采用不同的垃圾回收算法。
- **G1 收集器**：打破了传统的分代内存布局，将整个堆内存划分为多个大小相等的独立区域（Region），每个 Region 可以是 Eden 区、Survivor 区或者老年代。同时，还有专门的 Humongous 区域用于存储大对象（大小超过 Region 一半的对象）。

**垃圾回收算法**



- **CMS 收集器**：采用 “标记 - 清除” 算法。其过程分为初始标记、并发标记、重新标记和并发清除四个阶段。初始标记和重新标记阶段需要 STW（Stop - The - World），并发标记和并发清除阶段可以与应用程序并发执行。
- **G1 收集器**：整体上采用 “标记 - 整理” 算法，局部（Region 之间）采用 “复制” 算法。在进行垃圾回收时，G1 会优先回收垃圾最多的 Region，从而保证在有限的时间内获得最高的垃圾回收效率。



**停顿控制**

- **CMS 收集器**：虽然尽量减少停顿时间，但在并发标记阶段可能会产生浮动垃圾，需要在下次垃圾回收时处理。并且，“标记 - 清除” 算法会产生内存碎片，当内存碎片过多时，可能会导致提前进行 Full GC，从而增加停顿时间。

- **G1 收集器**：通过可预测的停顿时间模型，用户可以指定一个垃圾回收的最大停顿时间。G1 会根据这个目标来选择要回收的 Region 数量和顺序，从而更好地控制停顿时间。

  



**空间利用率**

- **CMS 收集器**：由于采用 “标记 - 清除” 算法，会产生内存碎片，随着时间的推移，可能会导致无法分配连续的大内存空间，降低了内存的利用率。
- **G1 收集器**：采用 “标记 - 整理” 和 “复制” 算法，不会产生内存碎片，能够更有效地利用内存空间。

### G1 被提出的原因



- **大内存管理难题**：随着硬件技术的发展，服务器的内存越来越大。传统的垃圾收集器在处理大内存时效率较低，例如 CMS 收集器在大内存下容易出现内存碎片问题，导致频繁的 Full GC。G1 收集器通过将堆内存划分为多个 Region，能够更好地管理大内存，提高垃圾回收的效率。
- **停顿时间控制需求**：现代应用程序对响应时间的要求越来越高，需要垃圾收集器能够在更短的时间内完成垃圾回收。G1 收集器提供了可预测的停顿时间模型，能够根据用户指定的停顿时间来调整垃圾回收的策略，满足了应用程序对低延迟的需求。

### G1 取代 CMS 的原因



- **内存碎片问题**：CMS 收集器的 “标记 - 清除” 算法会产生大量的内存碎片，而 G1 收集器的 “标记 - 整理” 和 “复制” 算法可以避免内存碎片的产生，提高了内存的利用率，减少了因内存碎片导致的 Full GC。
- **停顿时间控制**：G1 收集器能够更好地控制垃圾回收的停顿时间，特别是在大内存环境下，相比 CMS 收集器具有更稳定的性能表现。
- **适应性更强**：G1 收集器在处理不同大小的堆内存和不同类型的应用程序时，具有更好的适应性。它可以根据应用程序的运行情况动态调整垃圾回收策略，而 CMS 收集器的适应性相对较差。

## redis的热key和大key概念

### 热 key 概念

**定义**

热 key 指的是在 Redis 中被频繁访问的 key。在实际应用场景中，可能会有一些热点数据，比如热门商品信息、热门新闻资讯等，这些数据对应的 Redis key 会被大量的请求频繁访问。



**产生原因**

- **业务特性**：某些业务场景下，部分数据本身就具有高热度。例如电商平台在促销活动期间，热门商品的库存信息、价格信息等会被大量用户同时访问；社交媒体平台上的热门话题相关数据也会成为热 key。

- **缓存设计**：不合理的缓存设计也可能导致热 key 的产生。比如将所有请求都集中到一个 key 上，或者没有对热点数据进行有效的拆分。

  

**影响**

- **性能瓶颈**：大量的请求集中在一个热 key 上，会导致 Redis 实例的某个节点负载过高，成为性能瓶颈。这可能会引起该节点的响应时间变长，甚至出现卡顿现象。
- **网络带宽压力**：热 key 的大量请求会占用大量的网络带宽，可能会影响其他业务的正常运行。
- **集群失衡**：在 Redis 集群环境中，热 key 可能会导致某个节点的负载远远高于其他节点，造成集群负载不均衡，降低整个集群的性能和可用性。
- 

**解决方案**

- **复制热 key**：将热 key 复制到多个 Redis 节点上，让请求分散到不同的节点，从而减轻单个节点的压力。
- **使用本地缓存**：在应用层使用本地缓存（如 Guava Cache），将热 key 的数据缓存到本地，减少对 Redis 的请求。
- **限流和熔断**：对热 key 的请求进行限流，防止过多的请求打在同一个 key 上。同时，设置熔断机制，当某个 key 的请求异常时，自动熔断对该 key 的访问。

### 大 key 概念

**定义**

大 key 通常是指存储的数据量过大的 key。在 Redis 中，不同的数据类型对于大 key 的定义有所不同：



- **字符串类型**：一般认为值的大小超过 10KB 就算是大 key。
- **哈希、列表、集合、有序集合类型**：元素数量过多（如超过 1000 个）或者整体占用内存过大也可视为大 key。

**产生原因**



- **数据未拆分**：在设计数据存储时，没有对数据进行合理的拆分，将大量的数据存储在一个 key 中。例如，将一个大的 JSON 对象或者大量的用户信息存储在一个字符串类型的 key 中。
- **批量操作**：在进行批量写入操作时，可能会不小心将大量的数据写入到一个 key 中。

**影响**



- **内存分布不均**：大 key 会占用大量的内存空间，可能导致 Redis 实例的内存分布不均衡，影响其他数据的存储。
- **删除和更新慢**：删除或更新大 key 时，会消耗大量的 CPU 时间，可能会导致 Redis 实例出现卡顿现象，影响其他操作的执行。
- **网络传输慢**：获取大 key 的数据时，会占用大量的网络带宽，导致数据传输时间变长，影响应用程序的响应速度。

**解决方案**

- **数据拆分**：将大 key 拆分成多个小 key 进行存储。例如，将一个大的哈希表拆分成多个小的哈希表，或者将一个大的列表拆分成多个小的列表。
- **定期清理**：定期清理过期或无用的大 key，释放内存空间。
- **异步处理**：对于大 key 的删除和更新操作，可以采用异步处理的方式，避免阻塞 Redis 主线程。



## 除了redis制作分布式锁还有什么方式？



### ZooKeeper

**原理**

ZooKeeper 是一个分布式协调服务，它基于树形结构的节点存储数据。实现分布式锁的基本思路是：在 ZooKeeper 中创建一个临时顺序节点，每个客户端在尝试获取锁时，会在指定的锁节点下创建一个临时顺序节点。然后，客户端获取该锁节点下的所有子节点，并判断自己创建的节点是否是序号最小的节点。如果是，则表示获取到了锁；否则，客户端需要监听比自己序号小的前一个节点的删除事件，当前一个节点被删除时，客户端再次检查自己是否是序号最小的节点，以此类推。

**示例代码（使用 Apache Curator 客户端）**

```java
import org.apache.curator.framework.CuratorFramework;
import org.apache.curator.framework.CuratorFrameworkFactory;
import org.apache.curator.framework.recipes.locks.InterProcessMutex;
import org.apache.curator.retry.ExponentialBackoffRetry;

public class ZooKeeperDistributedLockExample {
    private static final String ZOOKEEPER_CONNECTION_STRING = "localhost:2181";
    private static final String LOCK_PATH = "/distributed_lock";

    public static void main(String[] args) throws Exception {
        CuratorFramework client = CuratorFrameworkFactory.newClient(ZOOKEEPER_CONNECTION_STRING, new ExponentialBackoffRetry(1000, 3));
        client.start();

        InterProcessMutex lock = new InterProcessMutex(client, LOCK_PATH);
        try {
            if (lock.acquire(10, java.util.concurrent.TimeUnit.SECONDS)) {
                try {
                    // 执行业务逻辑
                    System.out.println("Acquired the lock and doing business logic...");
                } finally {
                    lock.release();
                }
            }
        } finally {
            client.close();
        }
    }
}
```

**优缺点**

- **优点**：可靠性高，ZooKeeper 具有良好的容错性和一致性；支持锁的可重入性；可以实现公平锁，按照客户端请求锁的顺序依次获取锁。
- **缺点**：性能相对较低，因为涉及到网络通信和节点的创建、删除操作；部署和维护成本较高。

### 基于 `SETNX` 命令（早期实现方式）

**原理**

`SETNX`（SET if Not eXists）是 Redis 的一个原子命令，当指定的 key 不存在时，将其值设置为给定的值，并返回 1；如果 key 已经存在，则不做任何操作，并返回 0。利用这个特性，可以通过 `SETNX` 来尝试获取锁，如果返回 1 则表示获取到锁，返回 0 则表示锁已被其他客户端持有。



```java
import redis.clients.jedis.Jedis;

public class RedisLockBySetNx {
    private static final String LOCK_KEY = "distributed_lock";
    private static final String LOCK_VALUE = "locked";
    private static final int EXPIRE_TIME = 10; // 锁的过期时间，单位：秒

    public static boolean acquireLock(Jedis jedis) {
        Long result = jedis.setnx(LOCK_KEY, LOCK_VALUE);
        if (result == 1) {
            // 设置锁的过期时间，防止死锁
            jedis.expire(LOCK_KEY, EXPIRE_TIME);
            return true;
        }
        return false;
    }

    public static void releaseLock(Jedis jedis) {
        jedis.del(LOCK_KEY);
    }

    public static void main(String[] args) {
        Jedis jedis = new Jedis("localhost", 6379);
        if (acquireLock(jedis)) {
            try {
                // 执行业务逻辑
                System.out.println("Acquired the lock and doing business logic...");
            } finally {
                releaseLock(jedis);
            }
        } else {
            System.out.println("Failed to acquire the lock.");
        }
        jedis.close();
    }
}
```

**缺点**

- `SETNX` 和 `EXPIRE` 不是原子操作，如果在执行 `SETNX` 成功后，在设置过期时间之前发生异常，**可能会导致锁永远不会过期，形成死锁**。

### 基于 `SET` 命令（推荐方式）

**原理**



从 Redis 2.6.12 版本开始，`SET` 命令支持了多个可选参数，包括 `NX`（等同于 `SETNX`）和 `EX`（设置过期时间，单位为秒）或 `PX`（设置过期时间，单位为毫秒），可以将设置 key 和设置过期时间作为一个原子操作执行。

示例代码（Java 语言，使用 Jedis 客户端）

```java
import redis.clients.jedis.Jedis;

public class RedisLockBySet {
    private static final String LOCK_KEY = "distributed_lock";
    private static final String LOCK_VALUE = "locked";
    private static final int EXPIRE_TIME = 10; // 锁的过期时间，单位：秒

    public static boolean acquireLock(Jedis jedis) {
        String result = jedis.set(LOCK_KEY, LOCK_VALUE, "NX", "EX", EXPIRE_TIME);
        return "OK".equals(result);
    }

    public static void releaseLock(Jedis jedis) {
        jedis.del(LOCK_KEY);
    }

    public static void main(String[] args) {
        Jedis jedis = new Jedis("localhost", 6379);
        if (acquireLock(jedis)) {
            try {
                // 执行业务逻辑
                System.out.println("Acquired the lock and doing business logic...");
            } finally {
                releaseLock(jedis);
            }
        } else {
            System.out.println("Failed to acquire the lock.");
        }
        jedis.close();
    }
}
```



注意事项

- 释放锁时，需要确保只有持有锁的客户端才能释放锁，避免误删其他客户端的锁。可以在设置锁的值时**，使用一个唯一的标识符**（如 UUID），在释放锁时先检查锁的值是否与自己持有的标识符一致。

## ioc容器与spring容器

IoC（Inversion of Control，控制反转）容器和 Spring 容器不是完全等同的概念，但它们之间存在紧密的联系，下面从概念、关系等方面进行详细解释：

**概念定义**

- IoC 容器
  - IoC 是一种设计原则，它将对象的创建、依赖关系的管理等控制权从代码中转移到外部容器。IoC 容器就是实现这一原则的具体工具，它负责对象的实例化、生命周期管理以及对象之间依赖关系的注入。IoC 容器是一个抽象的概念，不局限于特定的框架或技术，只要符合控制反转的思想，能完成对象管理和依赖注入功能的都可以称为 IoC 容器。
- Spring 容器
  - Spring 容器是 Spring 框架的核心组件之一，它是一个具体实现了 IoC 原则的容器。Spring 框架提供了多种类型的容器，如 `BeanFactory` 和 `ApplicationContext` ，它们能够管理 Spring 应用中的各种 Bean（组件），包括创建 Bean 实例、注入依赖、管理 Bean 的生命周期等。

**两者关系**

- Spring 容器是 IoC 容器的一种实现
  - Spring 容器是基于 IoC 思想开发的，它是众多 IoC 容器实现中的一个具体例子。Spring 容器通过 XML 配置文件、Java 注解等方式来定义和管理 Bean，实现了对象的创建和依赖注入的自动化，很好地体现了 IoC 原则。
- IoC 容器概念更宽泛
  - IoC 容器是一个通用的概念，除了 Spring 容器外，还有其他框架也实现了 IoC 容器，例如 Guice（Google 开发的轻量级 Java 依赖注入框架）、PicoContainer 等。这些框架都遵循 IoC 原则，提供了对象管理和依赖注入的功能，但它们的实现方式和特点可能与 Spring 容器有所不同。

## 如何判断自己的任务是cpu密集型还是io密集型

**定义区分**

- **CPU 密集型任务**：也称为计算密集型任务，这类任务主要特点是需要大量的 CPU 计算资源。任务执行过程中，CPU 一直处于忙碌状态，几乎没有空闲时间等待其他操作完成，例如数据加密解密、视频编码解码、科学计算等。
- **I/O 密集型任务**：这类任务主要的时间花费在 I/O 操作上，比如磁盘读写、网络请求等。在进行 I/O 操作时，CPU 处于空闲状态，等待 I/O 操作完成后再继续执行后续任务，像文件读写、数据库查询、网络爬虫等都属于 I/O 密集型任务。



## sql的in排序

数据量很多时的解决方式，批量in查询以及

## cas

## redis的solr脚本以及pilpline

## mongo和es技术选型上的区分

**数据模型与存储方式**

- MongoDB
  - **特点**：MongoDB 是面向文档的数据库，采用 BSON（二进制 JSON）格式存储数据。文档以键值对的形式组织，类似于 JSON 对象，支持嵌套结构，一个集合中的文档可以有不同的结构，具有很高的灵活性。
  - **优势**：适合存储半结构化或非结构化数据，如日志、用户信息等。开发人员可以根据业务需求动态调整文档结构，无需预先定义严格的表结构，开发效率高。
- Elasticsearch
  - **特点**：ES 是基于 Lucene 的分布式搜索引擎，数据以索引（Index）、类型（Type，在 7.x 版本后逐渐弃用）和文档（Document）的形式组织。文档是 JSON 格式，索引类似于关系数据库中的数据库，用于存储相关的文档。
  - **优势**：其倒排索引的存储结构使得全文搜索和分析非常高效，能够快速定位包含特定关键词的文档。





**查询与分析能力**

- MongoDB
  - **特点**：提供了丰富的查询操作符，支持范围查询、正则表达式查询等。可以使用聚合管道进行复杂的数据处理和分析，如分组、排序、统计等。
  - **优势**：对于需要进行复杂数据处理和聚合操作的场景，MongoDB 可以方便地实现。例如，统计某个时间段内用户的消费总额、按地区分组统计订单数量等。
- Elasticsearch
  - **特点**：强大的全文搜索功能是 ES 的核心优势，支持模糊搜索、高亮显示、自动补全、同义词搜索等。同时，ES 提供了丰富的聚合功能，如桶聚合、指标聚合等，可用于数据分析和可视化。
  - **优势**：在需要进行全文搜索和实时数据分析的场景中表现出色。例如，搜索引擎、日志分析、电商商品搜索等。



**分布式架构与扩展性**

- MongoDB
  - **特点**：支持分片集群和副本集。分片集群可以将数据分散存储在多个节点上，实现数据的水平扩展；副本集提供了数据的冗余备份和高可用性，当主节点故障时，副本节点可以自动切换为主节点。
  - **优势**：能够处理大规模数据的存储和读写请求，并且在数据量增长时可以方便地进行扩展。适用于需要处理大量数据写入和读取的场景，如电商订单系统、日志存储系统等。
- Elasticsearch
  - **特点**：天生就是分布式系统，数据会被自动分片并分布到多个节点上。ES 可以根据节点的负载情况自动进行分片的迁移和均衡，具有良好的扩展性和容错性。
  - **优势**：在处理大规模数据的搜索和分析时，能够快速响应用户的查询请求。同时，ES 支持动态扩展节点，随着数据量和查询请求的增加，可以方便地添加新的节点来提高系统的性能。



**性能特点**

- MongoDB
  - **特点**：在处理大量的写入操作时表现较好，尤其是对于批量写入和更新操作，MongoDB 可以通过批量操作减少网络开销，提高写入性能。
  - **优势**：适用于需要频繁写入数据的场景，如实时日志收集、传感器数据采集等。
- Elasticsearch
  - **特点**：在全文搜索和实时数据分析方面具有极高的性能，能够在毫秒级的时间内返回搜索结果。
  - **优势**：对于需要快速响应用户搜索请求的场景，如搜索引擎、商品搜索等，ES 是一个很好的选择。





适用场景

- MongoDB
  - 内容管理系统：存储文章、图片、视频等各种类型的内容，利用其灵活的数据模型可以方便地存储不同格式的内容信息。
  - 物联网平台：处理大量传感器产生的实时数据，MongoDB 的高写入性能和分布式架构能够满足物联网数据的存储和处理需求。
  - 移动应用后端：存储用户信息、应用日志等数据，方便开发人员根据业务需求动态调整数据结构。
- Elasticsearch
  - 搜索引擎：如电商网站的商品搜索、新闻网站的文章搜索等，利用 ES 的全文搜索功能可以快速定位用户需要的信息。
  - 日志分析系统：对系统日志、应用日志进行实时分析，通过 ES 的聚合功能可以统计错误日志的数量、分析用户行为等。
  - 商业智能分析：对业务数据进行实时分析和可视化，帮助企业快速了解业务状况，做出决策。



综上所述，MongoDB 更侧重于数据的存储和复杂数据处理，而 Elasticsearch 则专注于全文搜索和实时数据分析。在技术选型时，需要根据具体的业务需求、数据特点和性能要求来选择合适的数据库。

## AQS

## 注解的意义与区别

## spring的事务注解方式如何实现有哪几种

## JVM问题排查与调优经历&过程

**1. 确认 Java 进程内存占用情况**



- **使用 `top` 或 `htop` 命令**：可以实时查看系统中各个进程的资源占用情况，包括内存使用量。找到 Java 进程的 PID（进程 ID）。

```bash
top
# 按 'P' 键按 CPU 使用率排序，按 'M' 键按内存使用率排序
```



- **使用 `ps` 命令**：可以查看指定进程的详细信息，包括内存使用情况。

```bash
ps -p <PID> -o pid,%mem,%cpu,cmd
```

**2. 分析 Java 堆内存使用情况**

- **使用 `jstat` 命令**：可以实时监控 Java 堆内存的使用情况，包括各个区域（如 Eden、Survivor、Old 区）的使用量和垃圾回收情况。

```bash
jstat -gc <PID> <interval> <count>
# 例如，每 1 秒监控一次，共监控 10 次
jstat -gc <PID> 1000 10
```

- **使用 `jmap` 命令**：可以生成 Java 堆的转储文件（Heap Dump），用于后续的内存分析。

```bash
jmap -dump:format=b,file=heapdump.hprof <PID>
```

**3.分析堆转储文件**

- **使用 VisualVM 或 YourKit 等工具**：这些工具可以加载堆转储文件，分析内存中的对象分布、对象引用关系等，找出占用大量内存的对象和可能存在的内存泄漏问题。

**4. 检查代码中的内存泄漏问题**

- **常见的内存泄漏场景**：如未关闭的资源（如文件、数据库连接、网络连接等）、静态集合中持有对象引用、内部类持有外部类引用等。
- **使用代码分析工具**：如 SonarQube、FindBugs 等，帮助检测代码中可能存在的内存泄漏问题。

### 解决思路

1. **优化代码**

- **及时释放资源**：确保在使用完资源后及时关闭，例如使用 `try-with-resources` 语句来管理资源。

```java
try (FileInputStream fis = new FileInputStream("file.txt")) {
    // 使用文件输入流
} catch (IOException e) {
    e.printStackTrace();
}
```



- **避免静态集合中持有大量对象引用**：如果静态集合中存储了大量对象，并且这些对象不再使用时没有及时从集合中移除，会导致内存泄漏。



```java
public class StaticCollectionExample {
    private static final List<Object> staticList = new ArrayList<>();

    public static void addObject(Object obj) {
        staticList.add(obj);
    }

    public static void removeObject(Object obj) {
        staticList.remove(obj);
    }
}
```



- **避免内部类持有外部类引用**：如果内部类需要长时间存活，并且持有外部类的引用，可能会导致外部类对象无法被垃圾回收。可以使用静态内部类来避免这个问题。

```java
public class OuterClass {
    private int value;

    public OuterClass(int value) {
        this.value = value;
    }

    // 静态内部类
    public static class StaticInnerClass {
        public void doSomething() {
            // 不持有外部类引用
        }
    }
}
```



2. **调整 Java 堆内存参数**

- **增加堆内存大小**：如果是因为堆内存不足导致的内存问题，可以通过调整 `-Xmx` 和 `-Xms` 参数来增加堆内存的大小。

```bash
java -Xmx2048m -Xms1024m YourMainClass
```

- **调整垃圾回收器**：不同的垃圾回收器适用于不同的场景，可以根据应用的特点选择合适的垃圾回收器。例如，对于吞吐量要求较高的应用，可以选择 `Parallel` 垃圾回收器；对于响应时间要求较高的应用，可以选择 `CMS` 或 `G1` 垃圾回收器

```bash
# 使用 G1 垃圾回收器
java -XX:+UseG1GC YourMainClass
```



3. **优化数据结构和算法**



- **选择合适的数据结构**：根据实际需求选择合适的数据结构，避免使用占用大量内存的数据结构。例如，如果只需要存储少量数据，可以使用 `ArrayList`；如果需要频繁进行插入和删除操作，可以使用 `LinkedList`。
- **优化算法复杂度**：避免使用时间复杂度和空间复杂度较高的算法，减少内存的使用。

## 数据库的一致性与cap原则

### 最终一致性



- **定义**：在分布式系统中，数据更新操作后，不同节点上的数据副本可能不会立即保持一致，但在经过一段时间的异步传播和处理后，最终会达到一致的状态。这意味着在数据更新后的短时间内，不同节点上的数据可能存在差异，但随着时间推移，系统会保证数据最终达到一致。
- **实现原理**：通常依靠各种异步复制、消息队列、分布式事务等技术来实现。例如，在分布式数据库中，当一个节点更新了数据后，会通过异步复制机制将更新操作传播到其他节点，虽然这个传播过程可能存在延迟，但最终所有节点都会应用这些更新，从而实现数据的最终一致性。

### CAP 定理

- 定义

  ：在分布式系统中，一致性（Consistency）、可用性（Availability）、分区容错性（Partition Tolerance）这三个基本需求，最多只能同时满足其中两个。

  - **一致性（Consistency）**：在分布式系统中的所有数据备份，在同一时刻是否同样的值。即更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致。
  - **可用性（Availability）**：系统提供的服务必须一直处于可用的状态，对于用户的每一个操作请求，总是能够在有限的时间内返回结果。
  - **分区容错性（Partition Tolerance）**：分布式系统在遇到任何网络分区故障的时候，仍然能够保证对外提供满足一致性和可用性的服务，除非整个网络环境都发生了故障。

- 三者关系

  - **CA without P**：如果不考虑分区容错性，即假设网络不会出现分区故障，那么可以同时实现一致性和可用性。比如在单一的数据库系统中，没有网络分区的问题，就可以通过事务机制等保证数据的一致性，同时也能保证系统的高可用性。
  - **CP without A**：当强调一致性和分区容错性时，可能会牺牲可用性。例如，在分布式数据库中，如果发生网络分区，为了保证数据一致性，系统可能会暂停部分服务，等待数据同步完成，这期间就会影响系统的可用性。
  - **AP without C**：如果注重可用性和分区容错性，就可能无法保证强一致性，只能实现最终一致性。如一些大规模的分布式缓存系统，为了保证在网络分区等情况下的高可用性，会允许数据在一定时间内存在不一致性，通过异步的方式来逐渐实现数据的最终一致性。



在实际的数据库设计和分布式系统架构中，需要根据具体的业务需求和场景来在 CAP 的三个要素中进行权衡和选择，以达到最优的系统性能和数据可靠性。

## 面试总结

### 阿里

分布式锁实现方式，除了redis还有啥
es原理，倒排索引什么原理
redis热 key大key
G1和CMS的区别
io和cpu密集型任务的区别
jvm的元空间
一个项目里有多个spring容器
kafka的原理
hashmap数组链表，头插尾插
concurrentHashMap原理
AQS
linux查看内存进程线程,TOP命令
redis实现锁的过程
redis缓存淘汰策略lru，lfu，区别
什么是粗排精排
ioc/aop

有没有遇到过死锁，如何解决死锁

死锁在系统资源消耗上的表现为什么？在没有充足接口日志支持的情况下如何使用linux解决系统资源开销问题

观察者模式，适配器模式有了解吗